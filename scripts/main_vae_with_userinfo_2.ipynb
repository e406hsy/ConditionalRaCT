{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"main_vae_with_userinfo_2.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"cS2B8ZR5uktb","colab_type":"text"},"source":["# Prerequisite"]},{"cell_type":"markdown","metadata":{"id":"z9MTKaptG_bD","colab_type":"text"},"source":["### step 1"]},{"cell_type":"markdown","metadata":{"id":"ZofEgqsxF6BZ","colab_type":"text"},"source":["download files from https://github.com/samlobel/RaCT_CF"]},{"cell_type":"markdown","metadata":{"id":"t-2cWSflHB5o","colab_type":"text"},"source":["### step 2"]},{"cell_type":"markdown","metadata":{"id":"GDjrwHecIFS8","colab_type":"text"},"source":["run setup_data.py\n","\n","```\n","python setup_data.py\n","```\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Gs-Kq67CHGg9","colab_type":"text"},"source":["### step 3"]},{"cell_type":"markdown","metadata":{"id":"paf3YBTpGQIH","colab_type":"text"},"source":["open *'utils/training.py'* change all *'.'* into your gdrive directory *'/content/gdrive/My drive/(YOUR DIRECTORY PATH)/utils'*"]},{"cell_type":"markdown","metadata":{"id":"Z2deEgFeHepx","colab_type":"text"},"source":["### step4"]},{"cell_type":"markdown","metadata":{"id":"mAk0_E0MHmgT","colab_type":"text"},"source":["upload to your gdrive"]},{"cell_type":"markdown","metadata":{"id":"-EL7s-ztFz6V","colab_type":"text"},"source":["# main_vae_with_userinfo"]},{"cell_type":"code","metadata":{"id":"-_Q215FgnYLD","colab_type":"code","outputId":"0a4e1c67-5a0b-4101-f43a-591b8e884b88","executionInfo":{"status":"ok","timestamp":1574749851469,"user_tz":-540,"elapsed":21021,"user":{"displayName":"홍순용","photoUrl":"","userId":"15027350610357707898"}},"colab":{"base_uri":"https://localhost:8080/","height":125}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive/')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qHaU4CRgdPPa","colab_type":"code","colab":{}},"source":["%tensorflow_version 1.x"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ppkNJLO5uBLm","colab_type":"code","outputId":"7a8f0fc5-b56d-4450-f610-4c5e4eb7c32d","executionInfo":{"status":"ok","timestamp":1574749857611,"user_tz":-540,"elapsed":27144,"user":{"displayName":"홍순용","photoUrl":"","userId":"15027350610357707898"}},"colab":{"base_uri":"https://localhost:8080/","height":158}},"source":["import sys\n","import os\n","UTILS_DIR = '/content/gdrive/My Drive/RaCT_CF-master/RaCT_CF-master/utils/'\n","sys.path.insert(1, UTILS_DIR)\n","from training import train, test"],"execution_count":3,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:\n","The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","  * https://github.com/tensorflow/io (for I/O related ops)\n","If you depend on functionality not listed there, please file an issue.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"en4GbLT0mj04","colab_type":"code","outputId":"a622271c-d62e-4ad0-cbed-552c3da9db3b","executionInfo":{"status":"ok","timestamp":1574749940514,"user_tz":-540,"elapsed":110035,"user":{"displayName":"홍순용","photoUrl":"","userId":"15027350610357707898"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["if __name__ == '__main__':\n","\n","    BREAK_EARLY = False\n","    BATCH_SIZE = 50\n","    for data_subdir in ['ml-100k']: # , 'netflix-prize', 'msd']:\n","        actor_path = \"VAE_ACTOR_TRAIN_{}\".format(data_subdir)\n","        mode = \"node2vec\"\n","        train(\n","            model_class='multi_vae_with_userinfo',\n","            data_subdir=data_subdir,\n","            n_epochs_pred_only=100,\n","            n_epochs_ac_only=0,\n","            n_epochs_pred_and_ac=0,\n","            max_kl=0.2,\n","            ac_reg_loss_scaler=0.0,\n","            actor_reg_loss_scaler=0.01,\n","            evaluation_metric=\"NDCG\",\n","            logging_frequency=50,\n","            batch_size=BATCH_SIZE,\n","            break_early=BREAK_EARLY,\n","            verbose=False,\n","            version_tag=\"FULL_RUN_ON_OTHER_DATASETS\",\n","            path_to_save_actor=actor_path,\n","            log_critic_training_error=False,\n","            mode=mode\n","        )\n","\n","        print(\"Now, hopefully on to testing...\")\n","\n","        test(\n","            model_class='multi_vae_with_userinfo',\n","            data_subdir=data_subdir,\n","            n_epochs_pred_only=100,\n","            n_epochs_ac_only=0,\n","            n_epochs_pred_and_ac=0,\n","            max_kl=0.2,\n","            ac_reg_loss_scaler=0.0,\n","            actor_reg_loss_scaler=0.01,\n","            evaluation_metric=\"NDCG\",\n","            batch_size=BATCH_SIZE,\n","            break_early=BREAK_EARLY,\n","            verbose=False,\n","            version_tag=\"FULL_RUN_ON_OTHER_DATASETS\",\n","            mode=mode\n","        )\n","\n","        print(\"On to round 2! Now we'll do the critic.\")\n","\n","        train(\n","            model_class='multi_vae_with_userinfo',\n","            data_subdir=data_subdir,\n","            n_epochs_pred_only=0,\n","            n_epochs_ac_only=50,\n","            n_epochs_pred_and_ac=50,\n","            max_kl=0.2,\n","            ac_reg_loss_scaler=0.0,\n","            actor_reg_loss_scaler=0.01,\n","            evaluation_metric=\"NDCG\",\n","            logging_frequency=50,\n","            batch_size=BATCH_SIZE,\n","            break_early=BREAK_EARLY,\n","            verbose=False,\n","            version_tag=\"FULL_RUN_ON_OTHER_DATASETS\",\n","            restore_trained_actor_path=actor_path,\n","            mode=mode\n","        )\n","\n","        print(\"Now, hopefully on to testing...\")\n","\n","        test(\n","            model_class='multi_vae_with_userinfo',\n","            data_subdir=data_subdir,\n","            n_epochs_pred_only=0,\n","            n_epochs_ac_only=50,\n","            n_epochs_pred_and_ac=50,\n","            max_kl=0.2,\n","            ac_reg_loss_scaler=0.0,\n","            actor_reg_loss_scaler=0.01,\n","            evaluation_metric=\"NDCG\",\n","            batch_size=BATCH_SIZE,\n","            break_early=BREAK_EARLY,\n","            verbose=False,\n","            version_tag=\"FULL_RUN_ON_OTHER_DATASETS\",\n","            restore_trained_actor_path=actor_path,\n","            mode=mode\n","        )\n","\n","\n","    print(\"Bye bye\")\n","    exit()"],"execution_count":4,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /content/gdrive/My Drive/RaCT_CF-master/RaCT_CF-master/utils/training.py:278: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n","\n","WARNING:tensorflow:From /content/gdrive/My Drive/RaCT_CF-master/RaCT_CF-master/utils/training.py:281: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n","\n","n_items: 1415\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n","  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"],"name":"stderr"},{"output_type":"stream","text":["node2vec mode\n","WARNING:tensorflow:From /content/gdrive/My Drive/RaCT_CF-master/RaCT_CF-master/utils/training.py:305: The name tf.data.Iterator is deprecated. Please use tf.compat.v1.data.Iterator instead.\n","\n","WARNING:tensorflow:From /content/gdrive/My Drive/RaCT_CF-master/RaCT_CF-master/utils/training.py:305: DatasetV1.output_types (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.data.get_output_types(dataset)`.\n","WARNING:tensorflow:From /content/gdrive/My Drive/RaCT_CF-master/RaCT_CF-master/utils/training.py:306: DatasetV1.output_shapes (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.data.get_output_shapes(dataset)`.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/ops/iterator_ops.py:347: Iterator.output_types (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.data.get_output_types(iterator)`.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/ops/iterator_ops.py:348: Iterator.output_shapes (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.data.get_output_shapes(iterator)`.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/ops/iterator_ops.py:350: Iterator.output_classes (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.data.get_output_classes(iterator)`.\n","setting attribute omit_num_unseen_from_critic to False\n","setting attribute omit_num_seen_from_critic to False\n","setting attribute ac_reg_loss_scaler to 0.0\n","setting attribute lr_ac to 2e-06\n","setting attribute lr_critic to 0.0001\n","setting attribute lr_actor to 0.001\n","setting attribute evaluation_metric to NDCG\n","setting attribute batch_size to 50\n","setting attribute epochs_to_anneal_over to 50\n","setting attribute anneal_cap to 0.2\n","setting attribute input_dim to 1415\n","setting attribute heldout_batch to Tensor(\"IteratorGetNext:1\", shape=(50, 1465), dtype=float32)\n","setting attribute batch_of_users to Tensor(\"IteratorGetNext:0\", shape=(50, 1465), dtype=float32)\n","WARNING:tensorflow:From /content/gdrive/My Drive/RaCT_CF-master/RaCT_CF-master/utils/base_models.py:40: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n","\n","WARNING:tensorflow:From /content/gdrive/My Drive/RaCT_CF-master/RaCT_CF-master/utils/base_models.py:301: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n","\n","WARNING:tensorflow:From /content/gdrive/My Drive/RaCT_CF-master/RaCT_CF-master/utils/models.py:181: Bernoulli.__init__ (from tensorflow.python.ops.distributions.bernoulli) is deprecated and will be removed after 2019-01-01.\n","Instructions for updating:\n","The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/distributions/bernoulli.py:97: Distribution.__init__ (from tensorflow.python.ops.distributions.distribution) is deprecated and will be removed after 2019-01-01.\n","Instructions for updating:\n","The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1866: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.__call__` method instead.\n","WARNING:tensorflow:From /content/gdrive/My Drive/RaCT_CF-master/RaCT_CF-master/utils/base_models.py:730: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n","\n","WARNING:tensorflow:From /content/gdrive/My Drive/RaCT_CF-master/RaCT_CF-master/utils/base_models.py:50: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n","\n","WARNING:tensorflow:From /content/gdrive/My Drive/RaCT_CF-master/RaCT_CF-master/utils/base_models.py:51: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n","\n","NOT OMITTING NUM SEEN\n","NOT OMITTING NUM UNSEEN\n","Always doing actor error, of course.\n","number of batch_norm_update_ops: 0\n","changed to 1e-4 from 1e-6, just so I know.\n","WARNING:tensorflow:From /content/gdrive/My Drive/RaCT_CF-master/RaCT_CF-master/utils/base_models.py:372: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","tf.py_func is deprecated in TF V2. Instead, there are two\n","    options available in V2.\n","    - tf.py_function takes a python function which manipulates tf eager\n","    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n","    an ndarray (just call tensor.numpy()) but having access to eager tensors\n","    means `tf.py_function`s can use accelerators such as GPUs as well as\n","    being differentiable using a gradient tape.\n","    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n","    (it is not differentiable, and manipulates numpy arrays). It drops the\n","    stateful argument making all functions stateful.\n","    \n","Evaluating with NDCG\n","changed to 1e-4 from 1e-6, just so I know.\n","number of BN update ops: 0\n","WARNING:tensorflow:From /content/gdrive/My Drive/RaCT_CF-master/RaCT_CF-master/utils/base_models.py:615: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/graph_editor/select.py:554: get_backward_walk_ops (from tensorflow.contrib.graph_editor.select) is deprecated and will be removed after 2019-06-06.\n","Instructions for updating:\n","Please use tensorflow.python.ops.op_selector.get_backward_walk_ops.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/decorator_utils.py:145: GraphKeys.VARIABLES (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.GraphKeys.GLOBAL_VARIABLES` instead.\n","WARNING:tensorflow:From /content/gdrive/My Drive/RaCT_CF-master/RaCT_CF-master/utils/models.py:121: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n","\n","INFO:tensorflow:Summary name ndcg@100 is illegal; using ndcg_100 instead.\n","WARNING:tensorflow:From /content/gdrive/My Drive/RaCT_CF-master/RaCT_CF-master/utils/base_models.py:253: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n","\n","WARNING:tensorflow:From /content/gdrive/My Drive/RaCT_CF-master/RaCT_CF-master/utils/base_models.py:106: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n","\n","log directory: /content/gdrive/My Drive/RaCT_CF-master/RaCT_CF-master/logging/ml-100k/multi_vae_with_userinfo/ac_reg_loss_scaler:0.0/actor_reg_loss_scaler:0.01/batch_size:50/batches_to_anneal_over:200000/break_early:False/epochs_to_anneal_over:50/evaluation_metric:NDCG/max_kl:0.2/min_kl:0.0/mode:node2vec/n_epochs_ac_only:0/n_epochs_pred_and_ac:0/n_epochs_pred_only:100/n_epochs_second_pred:0/omit_num_seen_from_critic:False/omit_num_unseen_from_critic:False/positive_weights:2.0/restore_trained_actor_path:None/verbose:False/version_tag:FULL_RUN_ON_OTHER_DATASETS\n","Existing logs found, removing to start anew\n","WARNING:tensorflow:From /content/gdrive/My Drive/RaCT_CF-master/RaCT_CF-master/utils/training.py:189: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n","\n","WARNING:tensorflow:From /content/gdrive/My Drive/RaCT_CF-master/RaCT_CF-master/utils/training.py:189: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","WARNING:tensorflow:From /content/gdrive/My Drive/RaCT_CF-master/RaCT_CF-master/utils/training.py:210: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.\n","\n","WARNING:tensorflow:From /content/gdrive/My Drive/RaCT_CF-master/RaCT_CF-master/utils/training.py:325: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","Not Restoring Actor.\n","WARNING:tensorflow:From /content/gdrive/My Drive/RaCT_CF-master/RaCT_CF-master/utils/training.py:336: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n","\n","Starting epoch 0\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.28561583161354065\n","new best on metric NDCG. Was -inf, now 0.28561583161354065. Saving\n","Saving actor as well.\n","Writing\n","Written\n","Starting epoch 1\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.31281861662864685\n","new best on metric NDCG. Was 0.28561583161354065, now 0.31281861662864685. Saving\n","Saving actor as well.\n","Writing\n","Written\n","Starting epoch 2\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.3528243601322174\n","new best on metric NDCG. Was 0.31281861662864685, now 0.3528243601322174. Saving\n","Saving actor as well.\n","Writing\n","Written\n","Starting epoch 3\n","initialized training.\n","Logging for batch 5\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.39087754487991333\n","new best on metric NDCG. Was 0.3528243601322174, now 0.39087754487991333. Saving\n","Saving actor as well.\n","Writing\n","Written\n","Starting epoch 4\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.44483402371406555\n","new best on metric NDCG. Was 0.39087754487991333, now 0.44483402371406555. Saving\n","Saving actor as well.\n","Writing\n","Written\n","Starting epoch 5\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.4430606961250305\n","Writing\n","Written\n","Starting epoch 6\n","initialized training.\n","Logging for batch 11\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.44898006319999695\n","new best on metric NDCG. Was 0.44483402371406555, now 0.44898006319999695. Saving\n","Saving actor as well.\n","Writing\n","Written\n","Starting epoch 7\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.48277586698532104\n","new best on metric NDCG. Was 0.44898006319999695, now 0.48277586698532104. Saving\n","Saving actor as well.\n","Writing\n","Written\n","Starting epoch 8\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.47309422492980957\n","Writing\n","Written\n","Starting epoch 9\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.4942174255847931\n","new best on metric NDCG. Was 0.48277586698532104, now 0.4942174255847931. Saving\n","Saving actor as well.\n","Writing\n","Written\n","Starting epoch 10\n","initialized training.\n","Logging for batch 2\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5007602572441101\n","new best on metric NDCG. Was 0.4942174255847931, now 0.5007602572441101. Saving\n","Saving actor as well.\n","Writing\n","Written\n","Starting epoch 11\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5100173354148865\n","new best on metric NDCG. Was 0.5007602572441101, now 0.5100173354148865. Saving\n","Saving actor as well.\n","Writing\n","Written\n","Starting epoch 12\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5064085125923157\n","Writing\n","Written\n","Starting epoch 13\n","initialized training.\n","Logging for batch 8\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.4991547763347626\n","Writing\n","Written\n","Starting epoch 14\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5145318508148193\n","new best on metric NDCG. Was 0.5100173354148865, now 0.5145318508148193. Saving\n","Saving actor as well.\n","Writing\n","Written\n","Starting epoch 15\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5056205987930298\n","Writing\n","Written\n","Starting epoch 16\n","initialized training.\n","Logging for batch 14\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.4966551959514618\n","Writing\n","Written\n","Starting epoch 17\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5182880759239197\n","new best on metric NDCG. Was 0.5145318508148193, now 0.5182880759239197. Saving\n","Saving actor as well.\n","Writing\n","Written\n","Starting epoch 18\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.515935480594635\n","Writing\n","Written\n","Starting epoch 19\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.4911642074584961\n","Writing\n","Written\n","Starting epoch 20\n","initialized training.\n","Logging for batch 5\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5012494921684265\n","Writing\n","Written\n","Starting epoch 21\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5113742351531982\n","Writing\n","Written\n","Starting epoch 22\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5019571781158447\n","Writing\n","Written\n","Starting epoch 23\n","initialized training.\n","Logging for batch 11\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5049094557762146\n","Writing\n","Written\n","Starting epoch 24\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5049317479133606\n","Writing\n","Written\n","Starting epoch 25\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.49782833456993103\n","Writing\n","Written\n","Starting epoch 26\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5046392679214478\n","Writing\n","Written\n","Starting epoch 27\n","initialized training.\n","Logging for batch 2\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5042840838432312\n","Writing\n","Written\n","Starting epoch 28\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5058839321136475\n","Writing\n","Written\n","Starting epoch 29\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.49647578597068787\n","Writing\n","Written\n","Starting epoch 30\n","initialized training.\n","Logging for batch 8\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.49850109219551086\n","Writing\n","Written\n","Starting epoch 31\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.48572593927383423\n","Writing\n","Written\n","Starting epoch 32\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.48894163966178894\n","Writing\n","Written\n","Starting epoch 33\n","initialized training.\n","Logging for batch 14\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5012547969818115\n","Writing\n","Written\n","Starting epoch 34\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5044074654579163\n","Writing\n","Written\n","Starting epoch 35\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.49573299288749695\n","Writing\n","Written\n","Starting epoch 36\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.49875926971435547\n","Writing\n","Written\n","Starting epoch 37\n","initialized training.\n","Logging for batch 5\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5014703273773193\n","Writing\n","Written\n","Starting epoch 38\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.4866080582141876\n","Writing\n","Written\n","Starting epoch 39\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.4894951581954956\n","Writing\n","Written\n","Starting epoch 40\n","initialized training.\n","Logging for batch 11\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.49076148867607117\n","Writing\n","Written\n","Starting epoch 41\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.49093830585479736\n","Writing\n","Written\n","Starting epoch 42\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.48939090967178345\n","Writing\n","Written\n","Starting epoch 43\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5022383332252502\n","Writing\n","Written\n","Starting epoch 44\n","initialized training.\n","Logging for batch 2\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.4900844097137451\n","Writing\n","Written\n","Starting epoch 45\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.48303890228271484\n","Writing\n","Written\n","Starting epoch 46\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.4840143620967865\n","Writing\n","Written\n","Starting epoch 47\n","initialized training.\n","Logging for batch 8\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.47881749272346497\n","Writing\n","Written\n","Starting epoch 48\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.48603197932243347\n","Writing\n","Written\n","Starting epoch 49\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.48737743496894836\n","Writing\n","Written\n","Starting epoch 50\n","initialized training.\n","Logging for batch 14\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.4887239933013916\n","Writing\n","Written\n","Starting epoch 51\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.4893266558647156\n","Writing\n","Written\n","Starting epoch 52\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.4862430989742279\n","Writing\n","Written\n","Starting epoch 53\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.4794030487537384\n","Writing\n","Written\n","Starting epoch 54\n","initialized training.\n","Logging for batch 5\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.4673096835613251\n","Writing\n","Written\n","Starting epoch 55\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.4757084548473358\n","Writing\n","Written\n","Starting epoch 56\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.4870907962322235\n","Writing\n","Written\n","Starting epoch 57\n","initialized training.\n","Logging for batch 11\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.47057366371154785\n","Writing\n","Written\n","Starting epoch 58\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.4705887734889984\n","Writing\n","Written\n","Starting epoch 59\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.48564547300338745\n","Writing\n","Written\n","Starting epoch 60\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.473694771528244\n","Writing\n","Written\n","Starting epoch 61\n","initialized training.\n","Logging for batch 2\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.4821628928184509\n","Writing\n","Written\n","Starting epoch 62\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.48092639446258545\n","Writing\n","Written\n","Starting epoch 63\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.4921378195285797\n","Writing\n","Written\n","Starting epoch 64\n","initialized training.\n","Logging for batch 8\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.47737380862236023\n","Writing\n","Written\n","Starting epoch 65\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.4757119417190552\n","Writing\n","Written\n","Starting epoch 66\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.47859126329421997\n","Writing\n","Written\n","Starting epoch 67\n","initialized training.\n","Logging for batch 14\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.4752368628978729\n","Writing\n","Written\n","Starting epoch 68\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.47997623682022095\n","Writing\n","Written\n","Starting epoch 69\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.4611569344997406\n","Writing\n","Written\n","Starting epoch 70\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.47006499767303467\n","Writing\n","Written\n","Starting epoch 71\n","initialized training.\n","Logging for batch 5\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.48500970005989075\n","Writing\n","Written\n","Starting epoch 72\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.47121649980545044\n","Writing\n","Written\n","Starting epoch 73\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.4757627546787262\n","Writing\n","Written\n","Starting epoch 74\n","initialized training.\n","Logging for batch 11\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.48405635356903076\n","Writing\n","Written\n","Starting epoch 75\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.4762163460254669\n","Writing\n","Written\n","Starting epoch 76\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.47546306252479553\n","Writing\n","Written\n","Starting epoch 77\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.4629146158695221\n","Writing\n","Written\n","Starting epoch 78\n","initialized training.\n","Logging for batch 2\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.46820712089538574\n","Writing\n","Written\n","Starting epoch 79\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.47882306575775146\n","Writing\n","Written\n","Starting epoch 80\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.4729980230331421\n","Writing\n","Written\n","Starting epoch 81\n","initialized training.\n","Logging for batch 8\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.4717683792114258\n","Writing\n","Written\n","Starting epoch 82\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.4740876257419586\n","Writing\n","Written\n","Starting epoch 83\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.47783714532852173\n","Writing\n","Written\n","Starting epoch 84\n","initialized training.\n","Logging for batch 14\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.4680722951889038\n","Writing\n","Written\n","Starting epoch 85\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.4589371979236603\n","Writing\n","Written\n","Starting epoch 86\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.4598711133003235\n","Writing\n","Written\n","Starting epoch 87\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.4533311724662781\n","Writing\n","Written\n","Starting epoch 88\n","initialized training.\n","Logging for batch 5\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.4559829831123352\n","Writing\n","Written\n","Starting epoch 89\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.46633514761924744\n","Writing\n","Written\n","Starting epoch 90\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.458871990442276\n","Writing\n","Written\n","Starting epoch 91\n","initialized training.\n","Logging for batch 11\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.4624899923801422\n","Writing\n","Written\n","Starting epoch 92\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.46421554684638977\n","Writing\n","Written\n","Starting epoch 93\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.4505891799926758\n","Writing\n","Written\n","Starting epoch 94\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.46951523423194885\n","Writing\n","Written\n","Starting epoch 95\n","initialized training.\n","Logging for batch 2\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.47195732593536377\n","Writing\n","Written\n","Starting epoch 96\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.4698503911495209\n","Writing\n","Written\n","Starting epoch 97\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.46718648076057434\n","Writing\n","Written\n","Starting epoch 98\n","initialized training.\n","Logging for batch 8\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.4856605529785156\n","Writing\n","Written\n","Starting epoch 99\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.46444591879844666\n","Writing\n","Written\n","Wow, it feels good to be down here. Done for real\n","Writing\n","Written\n","Now, hopefully on to testing...\n","n_items: 1415\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n","  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"],"name":"stderr"},{"output_type":"stream","text":["setting attribute omit_num_unseen_from_critic to False\n","setting attribute omit_num_seen_from_critic to False\n","setting attribute ac_reg_loss_scaler to 0.0\n","setting attribute lr_ac to 2e-06\n","setting attribute lr_critic to 0.0001\n","setting attribute lr_actor to 0.001\n","setting attribute evaluation_metric to NDCG\n","setting attribute batch_size to 50\n","setting attribute epochs_to_anneal_over to 50\n","setting attribute anneal_cap to 0.2\n","setting attribute input_dim to 1415\n","setting attribute heldout_batch to Tensor(\"IteratorGetNext:1\", shape=(50, 1465), dtype=float32)\n","setting attribute batch_of_users to Tensor(\"IteratorGetNext:0\", shape=(50, 1465), dtype=float32)\n","NOT OMITTING NUM SEEN\n","NOT OMITTING NUM UNSEEN\n","Always doing actor error, of course.\n","number of batch_norm_update_ops: 0\n","changed to 1e-4 from 1e-6, just so I know.\n","Evaluating with NDCG\n","changed to 1e-4 from 1e-6, just so I know.\n","number of BN update ops: 0\n","INFO:tensorflow:Summary name ndcg@100 is illegal; using ndcg_100 instead.\n","Test!\n","INFO:tensorflow:Restoring parameters from /content/gdrive/My Drive/RaCT_CF-master/RaCT_CF-master/checkpoints/ml-100k/multi_vae_with_userinfo/ac_reg_loss_scaler:0.0/actor_reg_loss_scaler:0.01/batch_size:50/batches_to_anneal_over:200000/break_early:False/epochs_to_anneal_over:50/evaluation_metric:NDCG/max_kl:0.2/min_kl:0.0/mode:node2vec/n_epochs_ac_only:0/n_epochs_pred_and_ac:0/n_epochs_pred_only:100/n_epochs_second_pred:0/omit_num_seen_from_critic:False/omit_num_unseen_from_critic:False/positive_weights:2.0/restore_trained_actor_path:None/verbose:False/version_tag:FULL_RUN_ON_OTHER_DATASETS/model\n","test batch.\n","test batch.\n","test batch.\n","Testing done. That broke it out of the loop.\n","Test UNNORMALIZED DCG@100=2.18676 (1.24327)\n","Test NDCG@100=0.46331 (0.01938)\n","Test Recall@50=0.57473 (0.19906)\n","Test Recall@020=0.42518 (0.18646)\n","Test NDCG@0200=0.50755 (0.13388)\n","Test NDCG@5=0.32120 (0.19591)\n","Test NDCG@3=0.34519 (0.22369)\n","Test NDCG@1=0.36000 (0.33941)\n","On to round 2! Now we'll do the critic.\n","n_items: 1415\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n","  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"],"name":"stderr"},{"output_type":"stream","text":["node2vec mode\n","setting attribute omit_num_unseen_from_critic to False\n","setting attribute omit_num_seen_from_critic to False\n","setting attribute ac_reg_loss_scaler to 0.0\n","setting attribute lr_ac to 2e-06\n","setting attribute lr_critic to 0.0001\n","setting attribute lr_actor to 0.001\n","setting attribute evaluation_metric to NDCG\n","setting attribute batch_size to 50\n","setting attribute epochs_to_anneal_over to 50\n","setting attribute anneal_cap to 0.2\n","setting attribute input_dim to 1415\n","setting attribute heldout_batch to Tensor(\"IteratorGetNext:1\", shape=(50, 1465), dtype=float32)\n","setting attribute batch_of_users to Tensor(\"IteratorGetNext:0\", shape=(50, 1465), dtype=float32)\n","NOT OMITTING NUM SEEN\n","NOT OMITTING NUM UNSEEN\n","Always doing actor error, of course.\n","number of batch_norm_update_ops: 0\n","changed to 1e-4 from 1e-6, just so I know.\n","Evaluating with NDCG\n","changed to 1e-4 from 1e-6, just so I know.\n","number of BN update ops: 0\n","INFO:tensorflow:Summary name ndcg@100 is illegal; using ndcg_100 instead.\n","log directory: /content/gdrive/My Drive/RaCT_CF-master/RaCT_CF-master/logging/ml-100k/multi_vae_with_userinfo/ac_reg_loss_scaler:0.0/actor_reg_loss_scaler:0.01/batch_size:50/batches_to_anneal_over:200000/break_early:False/epochs_to_anneal_over:50/evaluation_metric:NDCG/max_kl:0.2/min_kl:0.0/mode:node2vec/n_epochs_ac_only:50/n_epochs_pred_and_ac:50/n_epochs_pred_only:0/n_epochs_second_pred:0/omit_num_seen_from_critic:False/omit_num_unseen_from_critic:False/positive_weights:2.0/restore_trained_actor_path:VAE_ACTOR_TRAIN_ml-100k/verbose:False/version_tag:FULL_RUN_ON_OTHER_DATASETS\n","Existing logs found, removing to start anew\n","Restoring Actor!\n","INFO:tensorflow:Restoring parameters from VAE_ACTOR_TRAIN_ml-100k/model\n","WARNING:tensorflow:From /content/gdrive/My Drive/RaCT_CF-master/RaCT_CF-master/utils/training.py:331: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n","\n","Starting epoch 0\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5182880759239197\n","new best on metric NDCG. Was -inf, now 0.5182880759239197. Saving\n","Writing\n","Written\n","Starting epoch 1\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5182880759239197\n","Writing\n","Written\n","Starting epoch 2\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5182880759239197\n","Writing\n","Written\n","Starting epoch 3\n","initialized training.\n","Logging for batch 5\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5182880759239197\n","Writing\n","Written\n","Starting epoch 4\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5182880759239197\n","Writing\n","Written\n","Starting epoch 5\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5182880163192749\n","Writing\n","Written\n","Starting epoch 6\n","initialized training.\n","Logging for batch 11\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5182880759239197\n","Writing\n","Written\n","Starting epoch 7\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5182880759239197\n","Writing\n","Written\n","Starting epoch 8\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5182880759239197\n","Writing\n","Written\n","Starting epoch 9\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5182880759239197\n","Writing\n","Written\n","Starting epoch 10\n","initialized training.\n","Logging for batch 2\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5182881355285645\n","new best on metric NDCG. Was 0.5182880759239197, now 0.5182881355285645. Saving\n","Writing\n","Written\n","Starting epoch 11\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5182881355285645\n","Writing\n","Written\n","Starting epoch 12\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5182880759239197\n","Writing\n","Written\n","Starting epoch 13\n","initialized training.\n","Logging for batch 8\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5182880759239197\n","Writing\n","Written\n","Starting epoch 14\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5182880759239197\n","Writing\n","Written\n","Starting epoch 15\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5182881355285645\n","Writing\n","Written\n","Starting epoch 16\n","initialized training.\n","Logging for batch 14\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5182880759239197\n","Writing\n","Written\n","Starting epoch 17\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5182881355285645\n","Writing\n","Written\n","Starting epoch 18\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5182880759239197\n","Writing\n","Written\n","Starting epoch 19\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5182880759239197\n","Writing\n","Written\n","Starting epoch 20\n","initialized training.\n","Logging for batch 5\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5182880163192749\n","Writing\n","Written\n","Starting epoch 21\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5182881355285645\n","Writing\n","Written\n","Starting epoch 22\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5182880759239197\n","Writing\n","Written\n","Starting epoch 23\n","initialized training.\n","Logging for batch 11\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5182881355285645\n","Writing\n","Written\n","Starting epoch 24\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5182881355285645\n","Writing\n","Written\n","Starting epoch 25\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5182880759239197\n","Writing\n","Written\n","Starting epoch 26\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5182881355285645\n","Writing\n","Written\n","Starting epoch 27\n","initialized training.\n","Logging for batch 2\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5182881355285645\n","Writing\n","Written\n","Starting epoch 28\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5182880759239197\n","Writing\n","Written\n","Starting epoch 29\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5182880759239197\n","Writing\n","Written\n","Starting epoch 30\n","initialized training.\n","Logging for batch 8\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5182880759239197\n","Writing\n","Written\n","Starting epoch 31\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5182880759239197\n","Writing\n","Written\n","Starting epoch 32\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5182880163192749\n","Writing\n","Written\n","Starting epoch 33\n","initialized training.\n","Logging for batch 14\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5182880759239197\n","Writing\n","Written\n","Starting epoch 34\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5182880163192749\n","Writing\n","Written\n","Starting epoch 35\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5182881355285645\n","Writing\n","Written\n","Starting epoch 36\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5182880759239197\n","Writing\n","Written\n","Starting epoch 37\n","initialized training.\n","Logging for batch 5\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5182881355285645\n","Writing\n","Written\n","Starting epoch 38\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5182880759239197\n","Writing\n","Written\n","Starting epoch 39\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5182880163192749\n","Writing\n","Written\n","Starting epoch 40\n","initialized training.\n","Logging for batch 11\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5182880759239197\n","Writing\n","Written\n","Starting epoch 41\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5182880759239197\n","Writing\n","Written\n","Starting epoch 42\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5182880759239197\n","Writing\n","Written\n","Starting epoch 43\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5182881355285645\n","Writing\n","Written\n","Starting epoch 44\n","initialized training.\n","Logging for batch 2\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5182881355285645\n","Writing\n","Written\n","Starting epoch 45\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5182880759239197\n","Writing\n","Written\n","Starting epoch 46\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5182880759239197\n","Writing\n","Written\n","Starting epoch 47\n","initialized training.\n","Logging for batch 8\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5182880759239197\n","Writing\n","Written\n","Starting epoch 48\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5182880759239197\n","Writing\n","Written\n","Starting epoch 49\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5182880759239197\n","Writing\n","Written\n","Starting epoch 50\n","initialized training.\n","Logging for batch 14\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5180754065513611\n","Writing\n","Written\n","Starting epoch 51\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5176907777786255\n","Writing\n","Written\n","Starting epoch 52\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5177474617958069\n","Writing\n","Written\n","Starting epoch 53\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5174800753593445\n","Writing\n","Written\n","Starting epoch 54\n","initialized training.\n","Logging for batch 5\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5176724791526794\n","Writing\n","Written\n","Starting epoch 55\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5174947381019592\n","Writing\n","Written\n","Starting epoch 56\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5174878835678101\n","Writing\n","Written\n","Starting epoch 57\n","initialized training.\n","Logging for batch 11\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5173749327659607\n","Writing\n","Written\n","Starting epoch 58\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5171281695365906\n","Writing\n","Written\n","Starting epoch 59\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5171622633934021\n","Writing\n","Written\n","Starting epoch 60\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.517250120639801\n","Writing\n","Written\n","Starting epoch 61\n","initialized training.\n","Logging for batch 2\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5167519450187683\n","Writing\n","Written\n","Starting epoch 62\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5169111490249634\n","Writing\n","Written\n","Starting epoch 63\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5165996551513672\n","Writing\n","Written\n","Starting epoch 64\n","initialized training.\n","Logging for batch 8\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5165534019470215\n","Writing\n","Written\n","Starting epoch 65\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5165612697601318\n","Writing\n","Written\n","Starting epoch 66\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5164140462875366\n","Writing\n","Written\n","Starting epoch 67\n","initialized training.\n","Logging for batch 14\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5160983204841614\n","Writing\n","Written\n","Starting epoch 68\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5158746242523193\n","Writing\n","Written\n","Starting epoch 69\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5160424113273621\n","Writing\n","Written\n","Starting epoch 70\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5166277885437012\n","Writing\n","Written\n","Starting epoch 71\n","initialized training.\n","Logging for batch 5\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5159148573875427\n","Writing\n","Written\n","Starting epoch 72\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.516013503074646\n","Writing\n","Written\n","Starting epoch 73\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5163884162902832\n","Writing\n","Written\n","Starting epoch 74\n","initialized training.\n","Logging for batch 11\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5163925290107727\n","Writing\n","Written\n","Starting epoch 75\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.516501784324646\n","Writing\n","Written\n","Starting epoch 76\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.515988290309906\n","Writing\n","Written\n","Starting epoch 77\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5158246755599976\n","Writing\n","Written\n","Starting epoch 78\n","initialized training.\n","Logging for batch 2\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5158353447914124\n","Writing\n","Written\n","Starting epoch 79\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5154507756233215\n","Writing\n","Written\n","Starting epoch 80\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5156779289245605\n","Writing\n","Written\n","Starting epoch 81\n","initialized training.\n","Logging for batch 8\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5157312750816345\n","Writing\n","Written\n","Starting epoch 82\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5156084299087524\n","Writing\n","Written\n","Starting epoch 83\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5151050090789795\n","Writing\n","Written\n","Starting epoch 84\n","initialized training.\n","Logging for batch 14\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5156003832817078\n","Writing\n","Written\n","Starting epoch 85\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5158006548881531\n","Writing\n","Written\n","Starting epoch 86\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5156951546669006\n","Writing\n","Written\n","Starting epoch 87\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5150682330131531\n","Writing\n","Written\n","Starting epoch 88\n","initialized training.\n","Logging for batch 5\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5155074000358582\n","Writing\n","Written\n","Starting epoch 89\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5153482556343079\n","Writing\n","Written\n","Starting epoch 90\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.515518307685852\n","Writing\n","Written\n","Starting epoch 91\n","initialized training.\n","Logging for batch 11\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5157434344291687\n","Writing\n","Written\n","Starting epoch 92\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5155004858970642\n","Writing\n","Written\n","Starting epoch 93\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5147491693496704\n","Writing\n","Written\n","Starting epoch 94\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.515213131904602\n","Writing\n","Written\n","Starting epoch 95\n","initialized training.\n","Logging for batch 2\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5148543119430542\n","Writing\n","Written\n","Starting epoch 96\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5148729085922241\n","Writing\n","Written\n","Starting epoch 97\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5150277614593506\n","Writing\n","Written\n","Starting epoch 98\n","initialized training.\n","Logging for batch 8\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5150785446166992\n","Writing\n","Written\n","Starting epoch 99\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5150312185287476\n","Writing\n","Written\n","Wow, it feels good to be down here. Done for real\n","Writing\n","Written\n","Now, hopefully on to testing...\n","n_items: 1415\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n","  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"],"name":"stderr"},{"output_type":"stream","text":["setting attribute omit_num_unseen_from_critic to False\n","setting attribute omit_num_seen_from_critic to False\n","setting attribute ac_reg_loss_scaler to 0.0\n","setting attribute lr_ac to 2e-06\n","setting attribute lr_critic to 0.0001\n","setting attribute lr_actor to 0.001\n","setting attribute evaluation_metric to NDCG\n","setting attribute batch_size to 50\n","setting attribute epochs_to_anneal_over to 50\n","setting attribute anneal_cap to 0.2\n","setting attribute input_dim to 1415\n","setting attribute heldout_batch to Tensor(\"IteratorGetNext:1\", shape=(50, 1465), dtype=float32)\n","setting attribute batch_of_users to Tensor(\"IteratorGetNext:0\", shape=(50, 1465), dtype=float32)\n","NOT OMITTING NUM SEEN\n","NOT OMITTING NUM UNSEEN\n","Always doing actor error, of course.\n","number of batch_norm_update_ops: 0\n","changed to 1e-4 from 1e-6, just so I know.\n","Evaluating with NDCG\n","changed to 1e-4 from 1e-6, just so I know.\n","number of BN update ops: 0\n","INFO:tensorflow:Summary name ndcg@100 is illegal; using ndcg_100 instead.\n","Test!\n","INFO:tensorflow:Restoring parameters from /content/gdrive/My Drive/RaCT_CF-master/RaCT_CF-master/checkpoints/ml-100k/multi_vae_with_userinfo/ac_reg_loss_scaler:0.0/actor_reg_loss_scaler:0.01/batch_size:50/batches_to_anneal_over:200000/break_early:False/epochs_to_anneal_over:50/evaluation_metric:NDCG/max_kl:0.2/min_kl:0.0/mode:node2vec/n_epochs_ac_only:50/n_epochs_pred_and_ac:50/n_epochs_pred_only:0/n_epochs_second_pred:0/omit_num_seen_from_critic:False/omit_num_unseen_from_critic:False/positive_weights:2.0/restore_trained_actor_path:VAE_ACTOR_TRAIN_ml-100k/verbose:False/version_tag:FULL_RUN_ON_OTHER_DATASETS/model\n","test batch.\n","test batch.\n","test batch.\n","Testing done. That broke it out of the loop.\n","Test UNNORMALIZED DCG@100=2.18676 (1.24327)\n","Test NDCG@100=0.46331 (0.01938)\n","Test Recall@50=0.57473 (0.19906)\n","Test Recall@020=0.42518 (0.18646)\n","Test NDCG@0200=0.50755 (0.13388)\n","Test NDCG@5=0.32120 (0.19591)\n","Test NDCG@3=0.34519 (0.22369)\n","Test NDCG@1=0.36000 (0.33941)\n","Bye bye\n"],"name":"stdout"}]}]}