{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"main_vae.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"cS2B8ZR5uktb","colab_type":"text"},"source":["# Prerequisite"]},{"cell_type":"markdown","metadata":{"id":"z9MTKaptG_bD","colab_type":"text"},"source":["### step 1"]},{"cell_type":"markdown","metadata":{"id":"ZofEgqsxF6BZ","colab_type":"text"},"source":["download files from https://github.com/samlobel/RaCT_CF"]},{"cell_type":"markdown","metadata":{"id":"t-2cWSflHB5o","colab_type":"text"},"source":["### step 2"]},{"cell_type":"markdown","metadata":{"id":"GDjrwHecIFS8","colab_type":"text"},"source":["run setup_data.py\n","\n","```\n","python setup_data.py\n","```\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Gs-Kq67CHGg9","colab_type":"text"},"source":["### step 3"]},{"cell_type":"markdown","metadata":{"id":"paf3YBTpGQIH","colab_type":"text"},"source":["open *'utils/training.py'* change all *'.'* into your gdrive directory *'/content/gdrive/My drive/(YOUR DIRECTORY PATH)/utils'*"]},{"cell_type":"markdown","metadata":{"id":"Z2deEgFeHepx","colab_type":"text"},"source":["### step4"]},{"cell_type":"markdown","metadata":{"id":"mAk0_E0MHmgT","colab_type":"text"},"source":["upload to your gdrive"]},{"cell_type":"markdown","metadata":{"id":"-EL7s-ztFz6V","colab_type":"text"},"source":["# main_vae"]},{"cell_type":"code","metadata":{"id":"-_Q215FgnYLD","colab_type":"code","outputId":"8239ff2a-be4b-4819-eaa5-6851de2b5c54","executionInfo":{"status":"ok","timestamp":1574559982308,"user_tz":-540,"elapsed":18365,"user":{"displayName":"홍순용","photoUrl":"","userId":"15027350610357707898"}},"colab":{"base_uri":"https://localhost:8080/","height":125}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive/')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ppkNJLO5uBLm","colab_type":"code","outputId":"8a7fa3a3-b4e0-438e-ef64-d79871d40765","executionInfo":{"status":"ok","timestamp":1574559991150,"user_tz":-540,"elapsed":6755,"user":{"displayName":"홍순용","photoUrl":"","userId":"15027350610357707898"}},"colab":{"base_uri":"https://localhost:8080/","height":158}},"source":["%tensorflow_version 1.x\n","import sys\n","import os\n","UTILS_DIR = '/content/gdrive/My Drive/RaCT_CF-master/RaCT_CF-master/utils/'\n","sys.path.insert(1, UTILS_DIR)\n","\n","from training import train, test"],"execution_count":2,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:\n","The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","  * https://github.com/tensorflow/io (for I/O related ops)\n","If you depend on functionality not listed there, please file an issue.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"en4GbLT0mj04","colab_type":"code","outputId":"459d3929-5125-4162-c332-01d44fb99421","executionInfo":{"status":"ok","timestamp":1574560053330,"user_tz":-540,"elapsed":49215,"user":{"displayName":"홍순용","photoUrl":"","userId":"15027350610357707898"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["if __name__ == '__main__':\n","\n","    BREAK_EARLY = False\n","    BATCH_SIZE = 50\n","\n","    for data_subdir in ['ml-100k']: # , 'netflix-prize', 'msd']:\n","        actor_path = \"VAE_ACTOR_TRAIN_{}\".format(data_subdir)\n","        train(\n","            model_class='multi_vae',\n","            data_subdir=data_subdir,\n","            n_epochs_pred_only=100,\n","            n_epochs_ac_only=0,\n","            n_epochs_pred_and_ac=0,\n","            max_kl=0.2,\n","            ac_reg_loss_scaler=0.0,\n","            actor_reg_loss_scaler=0.01,\n","            evaluation_metric=\"NDCG\",\n","            logging_frequency=50,\n","            batch_size=BATCH_SIZE,\n","            break_early=BREAK_EARLY,\n","            verbose=False,\n","            version_tag=\"FULL_RUN_ON_OTHER_DATASETS\",\n","            path_to_save_actor=actor_path,\n","            log_critic_training_error=False,\n","        )\n","\n","        print(\"Now, hopefully on to testing...\")\n","\n","        test(\n","            model_class='multi_vae',\n","            data_subdir=data_subdir,\n","            n_epochs_pred_only=100,\n","            n_epochs_ac_only=0,\n","            n_epochs_pred_and_ac=0,\n","            max_kl=0.2,\n","            ac_reg_loss_scaler=0.0,\n","            actor_reg_loss_scaler=0.01,\n","            evaluation_metric=\"NDCG\",\n","            batch_size=BATCH_SIZE,\n","            break_early=BREAK_EARLY,\n","            verbose=False,\n","            version_tag=\"FULL_RUN_ON_OTHER_DATASETS\",\n","        )\n","\n","        print(\"On to round 2! Now we'll do the critic.\")\n","\n","        train(\n","            model_class='multi_vae',\n","            data_subdir=data_subdir,\n","            n_epochs_pred_only=0,\n","            n_epochs_ac_only=50,\n","            n_epochs_pred_and_ac=50,\n","            max_kl=0.2,\n","            ac_reg_loss_scaler=0.0,\n","            actor_reg_loss_scaler=0.01,\n","            evaluation_metric=\"NDCG\",\n","            logging_frequency=50,\n","            batch_size=BATCH_SIZE,\n","            break_early=BREAK_EARLY,\n","            verbose=False,\n","            version_tag=\"FULL_RUN_ON_OTHER_DATASETS\",\n","            restore_trained_actor_path=actor_path,\n","        )\n","\n","        print(\"Now, hopefully on to testing...\")\n","\n","        test(\n","            model_class='multi_vae',\n","            data_subdir=data_subdir,\n","            n_epochs_pred_only=0,\n","            n_epochs_ac_only=50,\n","            n_epochs_pred_and_ac=50,\n","            max_kl=0.2,\n","            ac_reg_loss_scaler=0.0,\n","            actor_reg_loss_scaler=0.01,\n","            evaluation_metric=\"NDCG\",\n","            batch_size=BATCH_SIZE,\n","            break_early=BREAK_EARLY,\n","            verbose=False,\n","            version_tag=\"FULL_RUN_ON_OTHER_DATASETS\",\n","            restore_trained_actor_path=actor_path,\n","        )\n","\n","\n","    print(\"Bye bye\")\n","    exit()"],"execution_count":4,"outputs":[{"output_type":"stream","text":["n_items: 1415\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n","  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /content/gdrive/My Drive/RaCT_CF-master/RaCT_CF-master/utils/data_loaders.py:243: The name tf.sparse_tensor_to_dense is deprecated. Please use tf.sparse.to_dense instead.\n","\n","WARNING:tensorflow:From /content/gdrive/My Drive/RaCT_CF-master/RaCT_CF-master/utils/training.py:300: The name tf.data.Iterator is deprecated. Please use tf.compat.v1.data.Iterator instead.\n","\n","WARNING:tensorflow:From /content/gdrive/My Drive/RaCT_CF-master/RaCT_CF-master/utils/training.py:300: DatasetV1.output_types (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.data.get_output_types(dataset)`.\n","WARNING:tensorflow:From /content/gdrive/My Drive/RaCT_CF-master/RaCT_CF-master/utils/training.py:301: DatasetV1.output_shapes (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.data.get_output_shapes(dataset)`.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/ops/iterator_ops.py:347: Iterator.output_types (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.data.get_output_types(iterator)`.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/ops/iterator_ops.py:348: Iterator.output_shapes (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.data.get_output_shapes(iterator)`.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/ops/iterator_ops.py:350: Iterator.output_classes (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.data.get_output_classes(iterator)`.\n","setting attribute omit_num_unseen_from_critic to False\n","setting attribute omit_num_seen_from_critic to False\n","setting attribute ac_reg_loss_scaler to 0.0\n","setting attribute lr_ac to 2e-06\n","setting attribute lr_critic to 0.0001\n","setting attribute lr_actor to 0.001\n","setting attribute evaluation_metric to NDCG\n","setting attribute batch_size to 50\n","setting attribute epochs_to_anneal_over to 50\n","setting attribute anneal_cap to 0.2\n","setting attribute input_dim to 1415\n","setting attribute heldout_batch to Tensor(\"IteratorGetNext:1\", shape=(50, 1415), dtype=float32)\n","setting attribute batch_of_users to Tensor(\"IteratorGetNext:0\", shape=(50, 1415), dtype=float32)\n","WARNING:tensorflow:From /content/gdrive/My Drive/RaCT_CF-master/RaCT_CF-master/utils/base_models.py:40: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n","\n","WARNING:tensorflow:From /content/gdrive/My Drive/RaCT_CF-master/RaCT_CF-master/utils/base_models.py:301: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n","\n","WARNING:tensorflow:From /content/gdrive/My Drive/RaCT_CF-master/RaCT_CF-master/utils/base_models.py:132: Bernoulli.__init__ (from tensorflow.python.ops.distributions.bernoulli) is deprecated and will be removed after 2019-01-01.\n","Instructions for updating:\n","The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/distributions/bernoulli.py:97: Distribution.__init__ (from tensorflow.python.ops.distributions.distribution) is deprecated and will be removed after 2019-01-01.\n","Instructions for updating:\n","The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1866: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.__call__` method instead.\n","WARNING:tensorflow:From /content/gdrive/My Drive/RaCT_CF-master/RaCT_CF-master/utils/base_models.py:730: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n","\n","WARNING:tensorflow:From /content/gdrive/My Drive/RaCT_CF-master/RaCT_CF-master/utils/base_models.py:50: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n","\n","WARNING:tensorflow:From /content/gdrive/My Drive/RaCT_CF-master/RaCT_CF-master/utils/base_models.py:51: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n","\n","NOT OMITTING NUM SEEN\n","NOT OMITTING NUM UNSEEN\n","Always doing actor error, of course.\n","number of batch_norm_update_ops: 0\n","changed to 1e-4 from 1e-6, just so I know.\n","WARNING:tensorflow:From /content/gdrive/My Drive/RaCT_CF-master/RaCT_CF-master/utils/base_models.py:372: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","tf.py_func is deprecated in TF V2. Instead, there are two\n","    options available in V2.\n","    - tf.py_function takes a python function which manipulates tf eager\n","    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n","    an ndarray (just call tensor.numpy()) but having access to eager tensors\n","    means `tf.py_function`s can use accelerators such as GPUs as well as\n","    being differentiable using a gradient tape.\n","    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n","    (it is not differentiable, and manipulates numpy arrays). It drops the\n","    stateful argument making all functions stateful.\n","    \n","Evaluating with NDCG\n","changed to 1e-4 from 1e-6, just so I know.\n","number of BN update ops: 0\n","WARNING:tensorflow:From /content/gdrive/My Drive/RaCT_CF-master/RaCT_CF-master/utils/base_models.py:615: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/graph_editor/select.py:554: get_backward_walk_ops (from tensorflow.contrib.graph_editor.select) is deprecated and will be removed after 2019-06-06.\n","Instructions for updating:\n","Please use tensorflow.python.ops.op_selector.get_backward_walk_ops.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/decorator_utils.py:145: GraphKeys.VARIABLES (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.GraphKeys.GLOBAL_VARIABLES` instead.\n","WARNING:tensorflow:From /content/gdrive/My Drive/RaCT_CF-master/RaCT_CF-master/utils/models.py:121: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n","\n","INFO:tensorflow:Summary name ndcg@100 is illegal; using ndcg_100 instead.\n","WARNING:tensorflow:From /content/gdrive/My Drive/RaCT_CF-master/RaCT_CF-master/utils/base_models.py:253: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n","\n","WARNING:tensorflow:From /content/gdrive/My Drive/RaCT_CF-master/RaCT_CF-master/utils/base_models.py:106: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n","\n","log directory: /content/gdrive/My Drive/RaCT_CF-master/RaCT_CF-master/logging/ml-100k/multi_vae/ac_reg_loss_scaler:0.0/actor_reg_loss_scaler:0.01/batch_size:50/batches_to_anneal_over:200000/break_early:False/epochs_to_anneal_over:50/evaluation_metric:NDCG/max_kl:0.2/min_kl:0.0/mode:basic/n_epochs_ac_only:0/n_epochs_pred_and_ac:0/n_epochs_pred_only:100/n_epochs_second_pred:0/omit_num_seen_from_critic:False/omit_num_unseen_from_critic:False/positive_weights:2.0/restore_trained_actor_path:None/verbose:False/version_tag:FULL_RUN_ON_OTHER_DATASETS\n","WARNING:tensorflow:From /content/gdrive/My Drive/RaCT_CF-master/RaCT_CF-master/utils/training.py:185: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n","\n","WARNING:tensorflow:From /content/gdrive/My Drive/RaCT_CF-master/RaCT_CF-master/utils/training.py:185: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","WARNING:tensorflow:From /content/gdrive/My Drive/RaCT_CF-master/RaCT_CF-master/utils/training.py:206: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.\n","\n","WARNING:tensorflow:From /content/gdrive/My Drive/RaCT_CF-master/RaCT_CF-master/utils/training.py:320: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","Not Restoring Actor.\n","WARNING:tensorflow:From /content/gdrive/My Drive/RaCT_CF-master/RaCT_CF-master/utils/training.py:331: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n","\n","Starting epoch 0\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.2627289891242981\n","new best on metric NDCG. Was -inf, now 0.2627289891242981. Saving\n","Saving actor as well.\n","Writing\n","Written\n","Starting epoch 1\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.32086676359176636\n","new best on metric NDCG. Was 0.2627289891242981, now 0.32086676359176636. Saving\n","Saving actor as well.\n","Writing\n","Written\n","Starting epoch 2\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.3710310757160187\n","new best on metric NDCG. Was 0.32086676359176636, now 0.3710310757160187. Saving\n","Saving actor as well.\n","Writing\n","Written\n","Starting epoch 3\n","initialized training.\n","Logging for batch 5\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.40936478972435\n","new best on metric NDCG. Was 0.3710310757160187, now 0.40936478972435. Saving\n","Saving actor as well.\n","Writing\n","Written\n","Starting epoch 4\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.4189966320991516\n","new best on metric NDCG. Was 0.40936478972435, now 0.4189966320991516. Saving\n","Saving actor as well.\n","Writing\n","Written\n","Starting epoch 5\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.4365006983280182\n","new best on metric NDCG. Was 0.4189966320991516, now 0.4365006983280182. Saving\n","Saving actor as well.\n","Writing\n","Written\n","Starting epoch 6\n","initialized training.\n","Logging for batch 11\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.46983474493026733\n","new best on metric NDCG. Was 0.4365006983280182, now 0.46983474493026733. Saving\n","Saving actor as well.\n","Writing\n","Written\n","Starting epoch 7\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.4629282057285309\n","Writing\n","Written\n","Starting epoch 8\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.4693833291530609\n","Writing\n","Written\n","Starting epoch 9\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.4848014712333679\n","new best on metric NDCG. Was 0.46983474493026733, now 0.4848014712333679. Saving\n","Saving actor as well.\n","Writing\n","Written\n","Starting epoch 10\n","initialized training.\n","Logging for batch 2\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.49631088972091675\n","new best on metric NDCG. Was 0.4848014712333679, now 0.49631088972091675. Saving\n","Saving actor as well.\n","Writing\n","Written\n","Starting epoch 11\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.49021339416503906\n","Writing\n","Written\n","Starting epoch 12\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.49863335490226746\n","new best on metric NDCG. Was 0.49631088972091675, now 0.49863335490226746. Saving\n","Saving actor as well.\n","Writing\n","Written\n","Starting epoch 13\n","initialized training.\n","Logging for batch 8\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5032607913017273\n","new best on metric NDCG. Was 0.49863335490226746, now 0.5032607913017273. Saving\n","Saving actor as well.\n","Writing\n","Written\n","Starting epoch 14\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5063493847846985\n","new best on metric NDCG. Was 0.5032607913017273, now 0.5063493847846985. Saving\n","Saving actor as well.\n","Writing\n","Written\n","Starting epoch 15\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.49597156047821045\n","Writing\n","Written\n","Starting epoch 16\n","initialized training.\n","Logging for batch 14\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5037682056427002\n","Writing\n","Written\n","Starting epoch 17\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.522454023361206\n","new best on metric NDCG. Was 0.5063493847846985, now 0.522454023361206. Saving\n","Saving actor as well.\n","Writing\n","Written\n","Starting epoch 18\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5011202096939087\n","Writing\n","Written\n","Starting epoch 19\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5182669162750244\n","Writing\n","Written\n","Starting epoch 20\n","initialized training.\n","Logging for batch 5\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5047939419746399\n","Writing\n","Written\n","Starting epoch 21\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5038717985153198\n","Writing\n","Written\n","Starting epoch 22\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5123337507247925\n","Writing\n","Written\n","Starting epoch 23\n","initialized training.\n","Logging for batch 11\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5016175508499146\n","Writing\n","Written\n","Starting epoch 24\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5103960633277893\n","Writing\n","Written\n","Starting epoch 25\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5151017904281616\n","Writing\n","Written\n","Starting epoch 26\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5021211504936218\n","Writing\n","Written\n","Starting epoch 27\n","initialized training.\n","Logging for batch 2\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5034124255180359\n","Writing\n","Written\n","Starting epoch 28\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5072940587997437\n","Writing\n","Written\n","Starting epoch 29\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.498504102230072\n","Writing\n","Written\n","Starting epoch 30\n","initialized training.\n","Logging for batch 8\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.504047691822052\n","Writing\n","Written\n","Starting epoch 31\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5091844797134399\n","Writing\n","Written\n","Starting epoch 32\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5024470686912537\n","Writing\n","Written\n","Starting epoch 33\n","initialized training.\n","Logging for batch 14\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.48393285274505615\n","Writing\n","Written\n","Starting epoch 34\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.4942293167114258\n","Writing\n","Written\n","Starting epoch 35\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.49508529901504517\n","Writing\n","Written\n","Starting epoch 36\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.497618168592453\n","Writing\n","Written\n","Starting epoch 37\n","initialized training.\n","Logging for batch 5\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.48680201172828674\n","Writing\n","Written\n","Starting epoch 38\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.4816417992115021\n","Writing\n","Written\n","Starting epoch 39\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.4871322512626648\n","Writing\n","Written\n","Starting epoch 40\n","initialized training.\n","Logging for batch 11\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.47510674595832825\n","Writing\n","Written\n","Starting epoch 41\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.4837193787097931\n","Writing\n","Written\n","Starting epoch 42\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.47580742835998535\n","Writing\n","Written\n","Starting epoch 43\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.4813477396965027\n","Writing\n","Written\n","Starting epoch 44\n","initialized training.\n","Logging for batch 2\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.49230721592903137\n","Writing\n","Written\n","Starting epoch 45\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.47745198011398315\n","Writing\n","Written\n","Starting epoch 46\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.49678337574005127\n","Writing\n","Written\n","Starting epoch 47\n","initialized training.\n","Logging for batch 8\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.4835164248943329\n","Writing\n","Written\n","Starting epoch 48\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.48798972368240356\n","Writing\n","Written\n","Starting epoch 49\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.48469221591949463\n","Writing\n","Written\n","Starting epoch 50\n","initialized training.\n","Logging for batch 14\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.48282501101493835\n","Writing\n","Written\n","Starting epoch 51\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.4903203845024109\n","Writing\n","Written\n","Starting epoch 52\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.4791848063468933\n","Writing\n","Written\n","Starting epoch 53\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.4787600338459015\n","Writing\n","Written\n","Starting epoch 54\n","initialized training.\n","Logging for batch 5\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.4747050106525421\n","Writing\n","Written\n","Starting epoch 55\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.47467464208602905\n","Writing\n","Written\n","Starting epoch 56\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.4686752259731293\n","Writing\n","Written\n","Starting epoch 57\n","initialized training.\n","Logging for batch 11\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.48109209537506104\n","Writing\n","Written\n","Starting epoch 58\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.476272314786911\n","Writing\n","Written\n","Starting epoch 59\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.4773889482021332\n","Writing\n","Written\n","Starting epoch 60\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.4755344092845917\n","Writing\n","Written\n","Starting epoch 61\n","initialized training.\n","Logging for batch 2\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.465968519449234\n","Writing\n","Written\n","Starting epoch 62\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.4631425142288208\n","Writing\n","Written\n","Starting epoch 63\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.4805704355239868\n","Writing\n","Written\n","Starting epoch 64\n","initialized training.\n","Logging for batch 8\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.45888611674308777\n","Writing\n","Written\n","Starting epoch 65\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.4834577143192291\n","Writing\n","Written\n","Starting epoch 66\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.46275410056114197\n","Writing\n","Written\n","Starting epoch 67\n","initialized training.\n","Logging for batch 14\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.4651566445827484\n","Writing\n","Written\n","Starting epoch 68\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.4724605083465576\n","Writing\n","Written\n","Starting epoch 69\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.4753313362598419\n","Writing\n","Written\n","Starting epoch 70\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.47031673789024353\n","Writing\n","Written\n","Starting epoch 71\n","initialized training.\n","Logging for batch 5\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.4748254716396332\n","Writing\n","Written\n","Starting epoch 72\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.4702349901199341\n","Writing\n","Written\n","Starting epoch 73\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.4651167690753937\n","Writing\n","Written\n","Starting epoch 74\n","initialized training.\n","Logging for batch 11\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.4593554735183716\n","Writing\n","Written\n","Starting epoch 75\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.4625440239906311\n","Writing\n","Written\n","Starting epoch 76\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.46290260553359985\n","Writing\n","Written\n","Starting epoch 77\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.4667111933231354\n","Writing\n","Written\n","Starting epoch 78\n","initialized training.\n","Logging for batch 2\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.4603062570095062\n","Writing\n","Written\n","Starting epoch 79\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.4707779288291931\n","Writing\n","Written\n","Starting epoch 80\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.4584465026855469\n","Writing\n","Written\n","Starting epoch 81\n","initialized training.\n","Logging for batch 8\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.4627628028392792\n","Writing\n","Written\n","Starting epoch 82\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.46003153920173645\n","Writing\n","Written\n","Starting epoch 83\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.47868308424949646\n","Writing\n","Written\n","Starting epoch 84\n","initialized training.\n","Logging for batch 14\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.4760938584804535\n","Writing\n","Written\n","Starting epoch 85\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.46702662110328674\n","Writing\n","Written\n","Starting epoch 86\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.46933063864707947\n","Writing\n","Written\n","Starting epoch 87\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.4583216905593872\n","Writing\n","Written\n","Starting epoch 88\n","initialized training.\n","Logging for batch 5\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.4634603261947632\n","Writing\n","Written\n","Starting epoch 89\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.4571707844734192\n","Writing\n","Written\n","Starting epoch 90\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.46609869599342346\n","Writing\n","Written\n","Starting epoch 91\n","initialized training.\n","Logging for batch 11\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.464796245098114\n","Writing\n","Written\n","Starting epoch 92\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.4600619375705719\n","Writing\n","Written\n","Starting epoch 93\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.4628974497318268\n","Writing\n","Written\n","Starting epoch 94\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.4677657186985016\n","Writing\n","Written\n","Starting epoch 95\n","initialized training.\n","Logging for batch 2\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.45826444029808044\n","Writing\n","Written\n","Starting epoch 96\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.4583403468132019\n","Writing\n","Written\n","Starting epoch 97\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.45632946491241455\n","Writing\n","Written\n","Starting epoch 98\n","initialized training.\n","Logging for batch 8\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.45318377017974854\n","Writing\n","Written\n","Starting epoch 99\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.45670413970947266\n","Writing\n","Written\n","Wow, it feels good to be down here. Done for real\n","Writing\n","Written\n","Now, hopefully on to testing...\n","n_items: 1415\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n","  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"],"name":"stderr"},{"output_type":"stream","text":["setting attribute omit_num_unseen_from_critic to False\n","setting attribute omit_num_seen_from_critic to False\n","setting attribute ac_reg_loss_scaler to 0.0\n","setting attribute lr_ac to 2e-06\n","setting attribute lr_critic to 0.0001\n","setting attribute lr_actor to 0.001\n","setting attribute evaluation_metric to NDCG\n","setting attribute batch_size to 50\n","setting attribute epochs_to_anneal_over to 50\n","setting attribute anneal_cap to 0.2\n","setting attribute input_dim to 1415\n","setting attribute heldout_batch to Tensor(\"IteratorGetNext:1\", shape=(50, 1415), dtype=float32)\n","setting attribute batch_of_users to Tensor(\"IteratorGetNext:0\", shape=(50, 1415), dtype=float32)\n","NOT OMITTING NUM SEEN\n","NOT OMITTING NUM UNSEEN\n","Always doing actor error, of course.\n","number of batch_norm_update_ops: 0\n","changed to 1e-4 from 1e-6, just so I know.\n","Evaluating with NDCG\n","changed to 1e-4 from 1e-6, just so I know.\n","number of BN update ops: 0\n","INFO:tensorflow:Summary name ndcg@100 is illegal; using ndcg_100 instead.\n","Test!\n","INFO:tensorflow:Restoring parameters from /content/gdrive/My Drive/RaCT_CF-master/RaCT_CF-master/checkpoints/ml-100k/multi_vae/ac_reg_loss_scaler:0.0/actor_reg_loss_scaler:0.01/batch_size:50/batches_to_anneal_over:200000/break_early:False/epochs_to_anneal_over:50/evaluation_metric:NDCG/max_kl:0.2/min_kl:0.0/mode:basic/n_epochs_ac_only:0/n_epochs_pred_and_ac:0/n_epochs_pred_only:100/n_epochs_second_pred:0/omit_num_seen_from_critic:False/omit_num_unseen_from_critic:False/positive_weights:2.0/restore_trained_actor_path:None/verbose:False/version_tag:FULL_RUN_ON_OTHER_DATASETS/model\n","test batch.\n","test batch.\n","test batch.\n","Testing done. That broke it out of the loop.\n","Test UNNORMALIZED DCG@100=2.11494 (1.22543)\n","Test NDCG@100=0.44916 (0.02023)\n","Test Recall@50=0.57846 (0.19961)\n","Test Recall@020=0.40965 (0.18307)\n","Test NDCG@0200=0.49098 (0.14177)\n","Test NDCG@5=0.28939 (0.19612)\n","Test NDCG@3=0.30010 (0.22122)\n","Test NDCG@1=0.34000 (0.33496)\n","On to round 2! Now we'll do the critic.\n","n_items: 1415\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n","  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"],"name":"stderr"},{"output_type":"stream","text":["setting attribute omit_num_unseen_from_critic to False\n","setting attribute omit_num_seen_from_critic to False\n","setting attribute ac_reg_loss_scaler to 0.0\n","setting attribute lr_ac to 2e-06\n","setting attribute lr_critic to 0.0001\n","setting attribute lr_actor to 0.001\n","setting attribute evaluation_metric to NDCG\n","setting attribute batch_size to 50\n","setting attribute epochs_to_anneal_over to 50\n","setting attribute anneal_cap to 0.2\n","setting attribute input_dim to 1415\n","setting attribute heldout_batch to Tensor(\"IteratorGetNext:1\", shape=(50, 1415), dtype=float32)\n","setting attribute batch_of_users to Tensor(\"IteratorGetNext:0\", shape=(50, 1415), dtype=float32)\n","NOT OMITTING NUM SEEN\n","NOT OMITTING NUM UNSEEN\n","Always doing actor error, of course.\n","number of batch_norm_update_ops: 0\n","changed to 1e-4 from 1e-6, just so I know.\n","Evaluating with NDCG\n","changed to 1e-4 from 1e-6, just so I know.\n","number of BN update ops: 0\n","INFO:tensorflow:Summary name ndcg@100 is illegal; using ndcg_100 instead.\n","log directory: /content/gdrive/My Drive/RaCT_CF-master/RaCT_CF-master/logging/ml-100k/multi_vae/ac_reg_loss_scaler:0.0/actor_reg_loss_scaler:0.01/batch_size:50/batches_to_anneal_over:200000/break_early:False/epochs_to_anneal_over:50/evaluation_metric:NDCG/max_kl:0.2/min_kl:0.0/mode:basic/n_epochs_ac_only:50/n_epochs_pred_and_ac:50/n_epochs_pred_only:0/n_epochs_second_pred:0/omit_num_seen_from_critic:False/omit_num_unseen_from_critic:False/positive_weights:2.0/restore_trained_actor_path:VAE_ACTOR_TRAIN_ml-100k/verbose:False/version_tag:FULL_RUN_ON_OTHER_DATASETS\n","Restoring Actor!\n","INFO:tensorflow:Restoring parameters from VAE_ACTOR_TRAIN_ml-100k/model\n","WARNING:tensorflow:From /content/gdrive/My Drive/RaCT_CF-master/RaCT_CF-master/utils/training.py:326: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n","\n","Starting epoch 0\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.522454023361206\n","new best on metric NDCG. Was -inf, now 0.522454023361206. Saving\n","Writing\n","Written\n","Starting epoch 1\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5224539637565613\n","Writing\n","Written\n","Starting epoch 2\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5224539637565613\n","Writing\n","Written\n","Starting epoch 3\n","initialized training.\n","Logging for batch 5\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5224539637565613\n","Writing\n","Written\n","Starting epoch 4\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.522454023361206\n","Writing\n","Written\n","Starting epoch 5\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.522454023361206\n","Writing\n","Written\n","Starting epoch 6\n","initialized training.\n","Logging for batch 11\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5224539637565613\n","Writing\n","Written\n","Starting epoch 7\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5224539637565613\n","Writing\n","Written\n","Starting epoch 8\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5224539637565613\n","Writing\n","Written\n","Starting epoch 9\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.522454023361206\n","Writing\n","Written\n","Starting epoch 10\n","initialized training.\n","Logging for batch 2\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5224539637565613\n","Writing\n","Written\n","Starting epoch 11\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5224539637565613\n","Writing\n","Written\n","Starting epoch 12\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.522454023361206\n","Writing\n","Written\n","Starting epoch 13\n","initialized training.\n","Logging for batch 8\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5224539637565613\n","Writing\n","Written\n","Starting epoch 14\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.522454023361206\n","Writing\n","Written\n","Starting epoch 15\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5224539637565613\n","Writing\n","Written\n","Starting epoch 16\n","initialized training.\n","Logging for batch 14\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5224539637565613\n","Writing\n","Written\n","Starting epoch 17\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5224539637565613\n","Writing\n","Written\n","Starting epoch 18\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5224539637565613\n","Writing\n","Written\n","Starting epoch 19\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5224539637565613\n","Writing\n","Written\n","Starting epoch 20\n","initialized training.\n","Logging for batch 5\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5224539637565613\n","Writing\n","Written\n","Starting epoch 21\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5224539637565613\n","Writing\n","Written\n","Starting epoch 22\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.522454023361206\n","Writing\n","Written\n","Starting epoch 23\n","initialized training.\n","Logging for batch 11\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5224539041519165\n","Writing\n","Written\n","Starting epoch 24\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.522454023361206\n","Writing\n","Written\n","Starting epoch 25\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.522454023361206\n","Writing\n","Written\n","Starting epoch 26\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5224539041519165\n","Writing\n","Written\n","Starting epoch 27\n","initialized training.\n","Logging for batch 2\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5224539637565613\n","Writing\n","Written\n","Starting epoch 28\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5224539637565613\n","Writing\n","Written\n","Starting epoch 29\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5224539041519165\n","Writing\n","Written\n","Starting epoch 30\n","initialized training.\n","Logging for batch 8\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5224539637565613\n","Writing\n","Written\n","Starting epoch 31\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5224539637565613\n","Writing\n","Written\n","Starting epoch 32\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5224539637565613\n","Writing\n","Written\n","Starting epoch 33\n","initialized training.\n","Logging for batch 14\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.522454023361206\n","Writing\n","Written\n","Starting epoch 34\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5224539637565613\n","Writing\n","Written\n","Starting epoch 35\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5224539637565613\n","Writing\n","Written\n","Starting epoch 36\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5224539041519165\n","Writing\n","Written\n","Starting epoch 37\n","initialized training.\n","Logging for batch 5\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5224539041519165\n","Writing\n","Written\n","Starting epoch 38\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.522454023361206\n","Writing\n","Written\n","Starting epoch 39\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5224539637565613\n","Writing\n","Written\n","Starting epoch 40\n","initialized training.\n","Logging for batch 11\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.522454023361206\n","Writing\n","Written\n","Starting epoch 41\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.522454023361206\n","Writing\n","Written\n","Starting epoch 42\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5224539637565613\n","Writing\n","Written\n","Starting epoch 43\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5224539637565613\n","Writing\n","Written\n","Starting epoch 44\n","initialized training.\n","Logging for batch 2\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.522454023361206\n","Writing\n","Written\n","Starting epoch 45\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5224539041519165\n","Writing\n","Written\n","Starting epoch 46\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5224539041519165\n","Writing\n","Written\n","Starting epoch 47\n","initialized training.\n","Logging for batch 8\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5224539637565613\n","Writing\n","Written\n","Starting epoch 48\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5224539041519165\n","Writing\n","Written\n","Starting epoch 49\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5224539637565613\n","Writing\n","Written\n","Starting epoch 50\n","initialized training.\n","Logging for batch 14\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5233253240585327\n","new best on metric NDCG. Was 0.522454023361206, now 0.5233253240585327. Saving\n","Writing\n","Written\n","Starting epoch 51\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5240604281425476\n","new best on metric NDCG. Was 0.5233253240585327, now 0.5240604281425476. Saving\n","Writing\n","Written\n","Starting epoch 52\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5253214836120605\n","new best on metric NDCG. Was 0.5240604281425476, now 0.5253214836120605. Saving\n","Writing\n","Written\n","Starting epoch 53\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5262991189956665\n","new best on metric NDCG. Was 0.5253214836120605, now 0.5262991189956665. Saving\n","Writing\n","Written\n","Starting epoch 54\n","initialized training.\n","Logging for batch 5\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5261819958686829\n","Writing\n","Written\n","Starting epoch 55\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5261132717132568\n","Writing\n","Written\n","Starting epoch 56\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5258535742759705\n","Writing\n","Written\n","Starting epoch 57\n","initialized training.\n","Logging for batch 11\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.525420069694519\n","Writing\n","Written\n","Starting epoch 58\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5263414978981018\n","new best on metric NDCG. Was 0.5262991189956665, now 0.5263414978981018. Saving\n","Writing\n","Written\n","Starting epoch 59\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5258157253265381\n","Writing\n","Written\n","Starting epoch 60\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5258258581161499\n","Writing\n","Written\n","Starting epoch 61\n","initialized training.\n","Logging for batch 2\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5257740020751953\n","Writing\n","Written\n","Starting epoch 62\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5252630114555359\n","Writing\n","Written\n","Starting epoch 63\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5252099633216858\n","Writing\n","Written\n","Starting epoch 64\n","initialized training.\n","Logging for batch 8\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5249937176704407\n","Writing\n","Written\n","Starting epoch 65\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5247160196304321\n","Writing\n","Written\n","Starting epoch 66\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5246866345405579\n","Writing\n","Written\n","Starting epoch 67\n","initialized training.\n","Logging for batch 14\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5248626470565796\n","Writing\n","Written\n","Starting epoch 68\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5251766443252563\n","Writing\n","Written\n","Starting epoch 69\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5250494480133057\n","Writing\n","Written\n","Starting epoch 70\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5249140858650208\n","Writing\n","Written\n","Starting epoch 71\n","initialized training.\n","Logging for batch 5\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5252352952957153\n","Writing\n","Written\n","Starting epoch 72\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.526735782623291\n","new best on metric NDCG. Was 0.5263414978981018, now 0.526735782623291. Saving\n","Writing\n","Written\n","Starting epoch 73\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5267850756645203\n","new best on metric NDCG. Was 0.526735782623291, now 0.5267850756645203. Saving\n","Writing\n","Written\n","Starting epoch 74\n","initialized training.\n","Logging for batch 11\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5267619490623474\n","Writing\n","Written\n","Starting epoch 75\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5271536111831665\n","new best on metric NDCG. Was 0.5267850756645203, now 0.5271536111831665. Saving\n","Writing\n","Written\n","Starting epoch 76\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5268425345420837\n","Writing\n","Written\n","Starting epoch 77\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5270020365715027\n","Writing\n","Written\n","Starting epoch 78\n","initialized training.\n","Logging for batch 2\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5267491340637207\n","Writing\n","Written\n","Starting epoch 79\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.525278627872467\n","Writing\n","Written\n","Starting epoch 80\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5261613726615906\n","Writing\n","Written\n","Starting epoch 81\n","initialized training.\n","Logging for batch 8\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5267896056175232\n","Writing\n","Written\n","Starting epoch 82\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5266575813293457\n","Writing\n","Written\n","Starting epoch 83\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.526370108127594\n","Writing\n","Written\n","Starting epoch 84\n","initialized training.\n","Logging for batch 14\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5263711214065552\n","Writing\n","Written\n","Starting epoch 85\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5260165929794312\n","Writing\n","Written\n","Starting epoch 86\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5261198878288269\n","Writing\n","Written\n","Starting epoch 87\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5261207222938538\n","Writing\n","Written\n","Starting epoch 88\n","initialized training.\n","Logging for batch 5\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5263950228691101\n","Writing\n","Written\n","Starting epoch 89\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5266932249069214\n","Writing\n","Written\n","Starting epoch 90\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5266088247299194\n","Writing\n","Written\n","Starting epoch 91\n","initialized training.\n","Logging for batch 11\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5260240435600281\n","Writing\n","Written\n","Starting epoch 92\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5265615582466125\n","Writing\n","Written\n","Starting epoch 93\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5267561674118042\n","Writing\n","Written\n","Starting epoch 94\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5267544388771057\n","Writing\n","Written\n","Starting epoch 95\n","initialized training.\n","Logging for batch 2\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5264267325401306\n","Writing\n","Written\n","Starting epoch 96\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5269790887832642\n","Writing\n","Written\n","Starting epoch 97\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5273692607879639\n","new best on metric NDCG. Was 0.5271536111831665, now 0.5273692607879639. Saving\n","Writing\n","Written\n","Starting epoch 98\n","initialized training.\n","Logging for batch 8\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5271179676055908\n","Writing\n","Written\n","Starting epoch 99\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5278241038322449\n","new best on metric NDCG. Was 0.5273692607879639, now 0.5278241038322449. Saving\n","Writing\n","Written\n","Wow, it feels good to be down here. Done for real\n","Writing\n","Written\n","Now, hopefully on to testing...\n","n_items: 1415\n","setting attribute omit_num_unseen_from_critic to False\n","setting attribute omit_num_seen_from_critic to False\n","setting attribute ac_reg_loss_scaler to 0.0\n","setting attribute lr_ac to 2e-06\n","setting attribute lr_critic to 0.0001\n","setting attribute lr_actor to 0.001\n","setting attribute evaluation_metric to NDCG\n","setting attribute batch_size to 50\n","setting attribute epochs_to_anneal_over to 50\n","setting attribute anneal_cap to 0.2\n","setting attribute input_dim to 1415\n","setting attribute heldout_batch to Tensor(\"IteratorGetNext:1\", shape=(50, 1415), dtype=float32)\n","setting attribute batch_of_users to Tensor(\"IteratorGetNext:0\", shape=(50, 1415), dtype=float32)\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n","  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"],"name":"stderr"},{"output_type":"stream","text":["NOT OMITTING NUM SEEN\n","NOT OMITTING NUM UNSEEN\n","Always doing actor error, of course.\n","number of batch_norm_update_ops: 0\n","changed to 1e-4 from 1e-6, just so I know.\n","Evaluating with NDCG\n","changed to 1e-4 from 1e-6, just so I know.\n","number of BN update ops: 0\n","INFO:tensorflow:Summary name ndcg@100 is illegal; using ndcg_100 instead.\n","Test!\n","INFO:tensorflow:Restoring parameters from /content/gdrive/My Drive/RaCT_CF-master/RaCT_CF-master/checkpoints/ml-100k/multi_vae/ac_reg_loss_scaler:0.0/actor_reg_loss_scaler:0.01/batch_size:50/batches_to_anneal_over:200000/break_early:False/epochs_to_anneal_over:50/evaluation_metric:NDCG/max_kl:0.2/min_kl:0.0/mode:basic/n_epochs_ac_only:50/n_epochs_pred_and_ac:50/n_epochs_pred_only:0/n_epochs_second_pred:0/omit_num_seen_from_critic:False/omit_num_unseen_from_critic:False/positive_weights:2.0/restore_trained_actor_path:VAE_ACTOR_TRAIN_ml-100k/verbose:False/version_tag:FULL_RUN_ON_OTHER_DATASETS/model\n","test batch.\n","test batch.\n","test batch.\n","Testing done. That broke it out of the loop.\n","Test UNNORMALIZED DCG@100=2.16985 (1.26166)\n","Test NDCG@100=0.45640 (0.01999)\n","Test Recall@50=0.57878 (0.19804)\n","Test Recall@020=0.41099 (0.17880)\n","Test NDCG@0200=0.49939 (0.14070)\n","Test NDCG@5=0.31976 (0.20700)\n","Test NDCG@3=0.32848 (0.24293)\n","Test NDCG@1=0.34000 (0.33496)\n","Bye bye\n"],"name":"stdout"}]}]}