{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"main_vae_with_userinfo.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"cS2B8ZR5uktb","colab_type":"text"},"source":["# Prerequisite"]},{"cell_type":"markdown","metadata":{"id":"z9MTKaptG_bD","colab_type":"text"},"source":["### step 1"]},{"cell_type":"markdown","metadata":{"id":"ZofEgqsxF6BZ","colab_type":"text"},"source":["download files from https://github.com/samlobel/RaCT_CF"]},{"cell_type":"markdown","metadata":{"id":"t-2cWSflHB5o","colab_type":"text"},"source":["### step 2"]},{"cell_type":"markdown","metadata":{"id":"GDjrwHecIFS8","colab_type":"text"},"source":["run setup_data.py\n","\n","```\n","python setup_data.py\n","```\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Gs-Kq67CHGg9","colab_type":"text"},"source":["### step 3"]},{"cell_type":"markdown","metadata":{"id":"paf3YBTpGQIH","colab_type":"text"},"source":["open *'utils/training.py'* change all *'.'* into your gdrive directory *'/content/gdrive/My drive/(YOUR DIRECTORY PATH)/utils'*"]},{"cell_type":"markdown","metadata":{"id":"Z2deEgFeHepx","colab_type":"text"},"source":["### step4"]},{"cell_type":"markdown","metadata":{"id":"mAk0_E0MHmgT","colab_type":"text"},"source":["upload to your gdrive"]},{"cell_type":"markdown","metadata":{"id":"-EL7s-ztFz6V","colab_type":"text"},"source":["# main_vae_with_userinfo"]},{"cell_type":"code","metadata":{"id":"-_Q215FgnYLD","colab_type":"code","outputId":"77f03cd7-0e16-4bf4-dd89-e44de0db96e2","executionInfo":{"status":"ok","timestamp":1574588755652,"user_tz":-540,"elapsed":24282,"user":{"displayName":"홍순용","photoUrl":"","userId":"15027350610357707898"}},"colab":{"base_uri":"https://localhost:8080/","height":125}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive/')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qHaU4CRgdPPa","colab_type":"code","colab":{}},"source":["%tensorflow_version 1.x"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ppkNJLO5uBLm","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":158},"outputId":"c98596f1-a92e-42a8-fd56-5c6042ac1b46","executionInfo":{"status":"ok","timestamp":1574588769154,"user_tz":-540,"elapsed":5953,"user":{"displayName":"홍순용","photoUrl":"","userId":"15027350610357707898"}}},"source":["import sys\n","import os\n","UTILS_DIR = '/content/gdrive/My Drive/RaCT_CF-master/RaCT_CF-master/utils/'\n","sys.path.insert(1, UTILS_DIR)\n","from training import train, test"],"execution_count":3,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:\n","The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","  * https://github.com/tensorflow/io (for I/O related ops)\n","If you depend on functionality not listed there, please file an issue.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"en4GbLT0mj04","colab_type":"code","outputId":"c7d990a9-a29b-4607-94d1-2ee95bc384c3","executionInfo":{"status":"ok","timestamp":1574588840919,"user_tz":-540,"elapsed":75230,"user":{"displayName":"홍순용","photoUrl":"","userId":"15027350610357707898"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["if __name__ == '__main__':\n","\n","    BREAK_EARLY = False\n","    BATCH_SIZE = 50\n","    for data_subdir in ['ml-100k']: # , 'netflix-prize', 'msd']:\n","        actor_path = \"VAE_ACTOR_TRAIN_{}\".format(data_subdir)\n","        mode = \"node2vec_user_info\"\n","        train(\n","            model_class='multi_vae_with_userinfo',\n","            data_subdir=data_subdir,\n","            n_epochs_pred_only=100,\n","            n_epochs_ac_only=0,\n","            n_epochs_pred_and_ac=0,\n","            max_kl=0.2,\n","            ac_reg_loss_scaler=0.0,\n","            actor_reg_loss_scaler=0.01,\n","            evaluation_metric=\"NDCG\",\n","            logging_frequency=50,\n","            batch_size=BATCH_SIZE,\n","            break_early=BREAK_EARLY,\n","            verbose=False,\n","            version_tag=\"FULL_RUN_ON_OTHER_DATASETS\",\n","            path_to_save_actor=actor_path,\n","            log_critic_training_error=False,\n","            mode=mode\n","        )\n","\n","        print(\"Now, hopefully on to testing...\")\n","\n","        test(\n","            model_class='multi_vae_with_userinfo',\n","            data_subdir=data_subdir,\n","            n_epochs_pred_only=100,\n","            n_epochs_ac_only=0,\n","            n_epochs_pred_and_ac=0,\n","            max_kl=0.2,\n","            ac_reg_loss_scaler=0.0,\n","            actor_reg_loss_scaler=0.01,\n","            evaluation_metric=\"NDCG\",\n","            batch_size=BATCH_SIZE,\n","            break_early=BREAK_EARLY,\n","            verbose=False,\n","            version_tag=\"FULL_RUN_ON_OTHER_DATASETS\",\n","            mode=mode\n","        )\n","\n","        print(\"On to round 2! Now we'll do the critic.\")\n","\n","        train(\n","            model_class='multi_vae_with_userinfo',\n","            data_subdir=data_subdir,\n","            n_epochs_pred_only=0,\n","            n_epochs_ac_only=50,\n","            n_epochs_pred_and_ac=50,\n","            max_kl=0.2,\n","            ac_reg_loss_scaler=0.0,\n","            actor_reg_loss_scaler=0.01,\n","            evaluation_metric=\"NDCG\",\n","            logging_frequency=50,\n","            batch_size=BATCH_SIZE,\n","            break_early=BREAK_EARLY,\n","            verbose=False,\n","            version_tag=\"FULL_RUN_ON_OTHER_DATASETS\",\n","            restore_trained_actor_path=actor_path,\n","            mode=mode\n","        )\n","\n","        print(\"Now, hopefully on to testing...\")\n","\n","        test(\n","            model_class='multi_vae_with_userinfo',\n","            data_subdir=data_subdir,\n","            n_epochs_pred_only=0,\n","            n_epochs_ac_only=50,\n","            n_epochs_pred_and_ac=50,\n","            max_kl=0.2,\n","            ac_reg_loss_scaler=0.0,\n","            actor_reg_loss_scaler=0.01,\n","            evaluation_metric=\"NDCG\",\n","            batch_size=BATCH_SIZE,\n","            break_early=BREAK_EARLY,\n","            verbose=False,\n","            version_tag=\"FULL_RUN_ON_OTHER_DATASETS\",\n","            restore_trained_actor_path=actor_path,\n","            mode=mode\n","        )\n","\n","\n","    print(\"Bye bye\")\n","    exit()"],"execution_count":4,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /content/gdrive/My Drive/RaCT_CF-master/RaCT_CF-master/utils/training.py:278: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n","\n","WARNING:tensorflow:From /content/gdrive/My Drive/RaCT_CF-master/RaCT_CF-master/utils/training.py:281: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n","\n","n_items: 1415\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n","  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /content/gdrive/My Drive/RaCT_CF-master/RaCT_CF-master/utils/training.py:305: The name tf.data.Iterator is deprecated. Please use tf.compat.v1.data.Iterator instead.\n","\n","WARNING:tensorflow:From /content/gdrive/My Drive/RaCT_CF-master/RaCT_CF-master/utils/training.py:305: DatasetV1.output_types (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.data.get_output_types(dataset)`.\n","WARNING:tensorflow:From /content/gdrive/My Drive/RaCT_CF-master/RaCT_CF-master/utils/training.py:306: DatasetV1.output_shapes (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.data.get_output_shapes(dataset)`.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/ops/iterator_ops.py:347: Iterator.output_types (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.data.get_output_types(iterator)`.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/ops/iterator_ops.py:348: Iterator.output_shapes (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.data.get_output_shapes(iterator)`.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/ops/iterator_ops.py:350: Iterator.output_classes (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.data.get_output_classes(iterator)`.\n","setting attribute omit_num_unseen_from_critic to False\n","setting attribute omit_num_seen_from_critic to False\n","setting attribute ac_reg_loss_scaler to 0.0\n","setting attribute lr_ac to 2e-06\n","setting attribute lr_critic to 0.0001\n","setting attribute lr_actor to 0.001\n","setting attribute evaluation_metric to NDCG\n","setting attribute batch_size to 50\n","setting attribute epochs_to_anneal_over to 50\n","setting attribute anneal_cap to 0.2\n","setting attribute input_dim to 1415\n","setting attribute heldout_batch to Tensor(\"IteratorGetNext:1\", shape=(50, 1465), dtype=float32)\n","setting attribute batch_of_users to Tensor(\"IteratorGetNext:0\", shape=(50, 1465), dtype=float32)\n","WARNING:tensorflow:From /content/gdrive/My Drive/RaCT_CF-master/RaCT_CF-master/utils/base_models.py:40: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n","\n","WARNING:tensorflow:From /content/gdrive/My Drive/RaCT_CF-master/RaCT_CF-master/utils/base_models.py:301: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n","\n","WARNING:tensorflow:From /content/gdrive/My Drive/RaCT_CF-master/RaCT_CF-master/utils/models.py:181: Bernoulli.__init__ (from tensorflow.python.ops.distributions.bernoulli) is deprecated and will be removed after 2019-01-01.\n","Instructions for updating:\n","The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/distributions/bernoulli.py:97: Distribution.__init__ (from tensorflow.python.ops.distributions.distribution) is deprecated and will be removed after 2019-01-01.\n","Instructions for updating:\n","The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1866: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.__call__` method instead.\n","WARNING:tensorflow:From /content/gdrive/My Drive/RaCT_CF-master/RaCT_CF-master/utils/base_models.py:730: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n","\n","WARNING:tensorflow:From /content/gdrive/My Drive/RaCT_CF-master/RaCT_CF-master/utils/base_models.py:50: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n","\n","WARNING:tensorflow:From /content/gdrive/My Drive/RaCT_CF-master/RaCT_CF-master/utils/base_models.py:51: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n","\n","NOT OMITTING NUM SEEN\n","NOT OMITTING NUM UNSEEN\n","Always doing actor error, of course.\n","number of batch_norm_update_ops: 0\n","changed to 1e-4 from 1e-6, just so I know.\n","WARNING:tensorflow:From /content/gdrive/My Drive/RaCT_CF-master/RaCT_CF-master/utils/base_models.py:372: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","tf.py_func is deprecated in TF V2. Instead, there are two\n","    options available in V2.\n","    - tf.py_function takes a python function which manipulates tf eager\n","    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n","    an ndarray (just call tensor.numpy()) but having access to eager tensors\n","    means `tf.py_function`s can use accelerators such as GPUs as well as\n","    being differentiable using a gradient tape.\n","    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n","    (it is not differentiable, and manipulates numpy arrays). It drops the\n","    stateful argument making all functions stateful.\n","    \n","Evaluating with NDCG\n","changed to 1e-4 from 1e-6, just so I know.\n","number of BN update ops: 0\n","WARNING:tensorflow:From /content/gdrive/My Drive/RaCT_CF-master/RaCT_CF-master/utils/base_models.py:615: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/graph_editor/select.py:554: get_backward_walk_ops (from tensorflow.contrib.graph_editor.select) is deprecated and will be removed after 2019-06-06.\n","Instructions for updating:\n","Please use tensorflow.python.ops.op_selector.get_backward_walk_ops.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/decorator_utils.py:145: GraphKeys.VARIABLES (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.GraphKeys.GLOBAL_VARIABLES` instead.\n","WARNING:tensorflow:From /content/gdrive/My Drive/RaCT_CF-master/RaCT_CF-master/utils/models.py:121: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n","\n","INFO:tensorflow:Summary name ndcg@100 is illegal; using ndcg_100 instead.\n","WARNING:tensorflow:From /content/gdrive/My Drive/RaCT_CF-master/RaCT_CF-master/utils/base_models.py:253: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n","\n","WARNING:tensorflow:From /content/gdrive/My Drive/RaCT_CF-master/RaCT_CF-master/utils/base_models.py:106: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n","\n","log directory: /content/gdrive/My Drive/RaCT_CF-master/RaCT_CF-master/logging/ml-100k/multi_vae_with_userinfo/ac_reg_loss_scaler:0.0/actor_reg_loss_scaler:0.01/batch_size:50/batches_to_anneal_over:200000/break_early:False/epochs_to_anneal_over:50/evaluation_metric:NDCG/max_kl:0.2/min_kl:0.0/mode:node2vec_user_info/n_epochs_ac_only:0/n_epochs_pred_and_ac:0/n_epochs_pred_only:100/n_epochs_second_pred:0/omit_num_seen_from_critic:False/omit_num_unseen_from_critic:False/positive_weights:2.0/restore_trained_actor_path:None/verbose:False/version_tag:FULL_RUN_ON_OTHER_DATASETS\n","Existing logs found, removing to start anew\n","WARNING:tensorflow:From /content/gdrive/My Drive/RaCT_CF-master/RaCT_CF-master/utils/training.py:189: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n","\n","WARNING:tensorflow:From /content/gdrive/My Drive/RaCT_CF-master/RaCT_CF-master/utils/training.py:189: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","WARNING:tensorflow:From /content/gdrive/My Drive/RaCT_CF-master/RaCT_CF-master/utils/training.py:210: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.\n","\n","WARNING:tensorflow:From /content/gdrive/My Drive/RaCT_CF-master/RaCT_CF-master/utils/training.py:325: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","Not Restoring Actor.\n","WARNING:tensorflow:From /content/gdrive/My Drive/RaCT_CF-master/RaCT_CF-master/utils/training.py:336: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n","\n","Starting epoch 0\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.2905346751213074\n","new best on metric NDCG. Was -inf, now 0.2905346751213074. Saving\n","Saving actor as well.\n","Writing\n","Written\n","Starting epoch 1\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.30640748143196106\n","new best on metric NDCG. Was 0.2905346751213074, now 0.30640748143196106. Saving\n","Saving actor as well.\n","Writing\n","Written\n","Starting epoch 2\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.3553275763988495\n","new best on metric NDCG. Was 0.30640748143196106, now 0.3553275763988495. Saving\n","Saving actor as well.\n","Writing\n","Written\n","Starting epoch 3\n","initialized training.\n","Logging for batch 5\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.4183901250362396\n","new best on metric NDCG. Was 0.3553275763988495, now 0.4183901250362396. Saving\n","Saving actor as well.\n","Writing\n","Written\n","Starting epoch 4\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.4280746877193451\n","new best on metric NDCG. Was 0.4183901250362396, now 0.4280746877193451. Saving\n","Saving actor as well.\n","Writing\n","Written\n","Starting epoch 5\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.4396507740020752\n","new best on metric NDCG. Was 0.4280746877193451, now 0.4396507740020752. Saving\n","Saving actor as well.\n","Writing\n","Written\n","Starting epoch 6\n","initialized training.\n","Logging for batch 11\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.463373064994812\n","new best on metric NDCG. Was 0.4396507740020752, now 0.463373064994812. Saving\n","Saving actor as well.\n","Writing\n","Written\n","Starting epoch 7\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.46082207560539246\n","Writing\n","Written\n","Starting epoch 8\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.49279671907424927\n","new best on metric NDCG. Was 0.463373064994812, now 0.49279671907424927. Saving\n","Saving actor as well.\n","Writing\n","Written\n","Starting epoch 9\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.4983213543891907\n","new best on metric NDCG. Was 0.49279671907424927, now 0.4983213543891907. Saving\n","Saving actor as well.\n","Writing\n","Written\n","Starting epoch 10\n","initialized training.\n","Logging for batch 2\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.4946928322315216\n","Writing\n","Written\n","Starting epoch 11\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.4970153868198395\n","Writing\n","Written\n","Starting epoch 12\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5094791650772095\n","new best on metric NDCG. Was 0.4983213543891907, now 0.5094791650772095. Saving\n","Saving actor as well.\n","Writing\n","Written\n","Starting epoch 13\n","initialized training.\n","Logging for batch 8\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5086174011230469\n","Writing\n","Written\n","Starting epoch 14\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5192546248435974\n","new best on metric NDCG. Was 0.5094791650772095, now 0.5192546248435974. Saving\n","Saving actor as well.\n","Writing\n","Written\n","Starting epoch 15\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.507053792476654\n","Writing\n","Written\n","Starting epoch 16\n","initialized training.\n","Logging for batch 14\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5123739838600159\n","Writing\n","Written\n","Starting epoch 17\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5166029930114746\n","Writing\n","Written\n","Starting epoch 18\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5159788727760315\n","Writing\n","Written\n","Starting epoch 19\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5173393487930298\n","Writing\n","Written\n","Starting epoch 20\n","initialized training.\n","Logging for batch 5\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.49628734588623047\n","Writing\n","Written\n","Starting epoch 21\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5199411511421204\n","new best on metric NDCG. Was 0.5192546248435974, now 0.5199411511421204. Saving\n","Saving actor as well.\n","Writing\n","Written\n","Starting epoch 22\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5156490802764893\n","Writing\n","Written\n","Starting epoch 23\n","initialized training.\n","Logging for batch 11\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5107074975967407\n","Writing\n","Written\n","Starting epoch 24\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5164946913719177\n","Writing\n","Written\n","Starting epoch 25\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5131139159202576\n","Writing\n","Written\n","Starting epoch 26\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5187596678733826\n","Writing\n","Written\n","Starting epoch 27\n","initialized training.\n","Logging for batch 2\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5029595494270325\n","Writing\n","Written\n","Starting epoch 28\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5049160122871399\n","Writing\n","Written\n","Starting epoch 29\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5010389685630798\n","Writing\n","Written\n","Starting epoch 30\n","initialized training.\n","Logging for batch 8\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5018689036369324\n","Writing\n","Written\n","Starting epoch 31\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5084186792373657\n","Writing\n","Written\n","Starting epoch 32\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.4961612820625305\n","Writing\n","Written\n","Starting epoch 33\n","initialized training.\n","Logging for batch 14\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5023102760314941\n","Writing\n","Written\n","Starting epoch 34\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.49892571568489075\n","Writing\n","Written\n","Starting epoch 35\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5034224987030029\n","Writing\n","Written\n","Starting epoch 36\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.48486918210983276\n","Writing\n","Written\n","Starting epoch 37\n","initialized training.\n","Logging for batch 5\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5000203251838684\n","Writing\n","Written\n","Starting epoch 38\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.48477160930633545\n","Writing\n","Written\n","Starting epoch 39\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.49526238441467285\n","Writing\n","Written\n","Starting epoch 40\n","initialized training.\n","Logging for batch 11\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.49385085701942444\n","Writing\n","Written\n","Starting epoch 41\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.49638766050338745\n","Writing\n","Written\n","Starting epoch 42\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5039684772491455\n","Writing\n","Written\n","Starting epoch 43\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.48993176221847534\n","Writing\n","Written\n","Starting epoch 44\n","initialized training.\n","Logging for batch 2\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.49522238969802856\n","Writing\n","Written\n","Starting epoch 45\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.4947059154510498\n","Writing\n","Written\n","Starting epoch 46\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.4880693852901459\n","Writing\n","Written\n","Starting epoch 47\n","initialized training.\n","Logging for batch 8\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.48005807399749756\n","Writing\n","Written\n","Starting epoch 48\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.49220511317253113\n","Writing\n","Written\n","Starting epoch 49\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.491108775138855\n","Writing\n","Written\n","Starting epoch 50\n","initialized training.\n","Logging for batch 14\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.47989243268966675\n","Writing\n","Written\n","Starting epoch 51\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.48107853531837463\n","Writing\n","Written\n","Starting epoch 52\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.49082785844802856\n","Writing\n","Written\n","Starting epoch 53\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.47063571214675903\n","Writing\n","Written\n","Starting epoch 54\n","initialized training.\n","Logging for batch 5\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.48010486364364624\n","Writing\n","Written\n","Starting epoch 55\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.4835852384567261\n","Writing\n","Written\n","Starting epoch 56\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.4829854965209961\n","Writing\n","Written\n","Starting epoch 57\n","initialized training.\n","Logging for batch 11\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.48272091150283813\n","Writing\n","Written\n","Starting epoch 58\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.4896513819694519\n","Writing\n","Written\n","Starting epoch 59\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.4943241477012634\n","Writing\n","Written\n","Starting epoch 60\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.4828808903694153\n","Writing\n","Written\n","Starting epoch 61\n","initialized training.\n","Logging for batch 2\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.48639702796936035\n","Writing\n","Written\n","Starting epoch 62\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.46997421979904175\n","Writing\n","Written\n","Starting epoch 63\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.4806300401687622\n","Writing\n","Written\n","Starting epoch 64\n","initialized training.\n","Logging for batch 8\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.47233203053474426\n","Writing\n","Written\n","Starting epoch 65\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.4846533238887787\n","Writing\n","Written\n","Starting epoch 66\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.4808444082736969\n","Writing\n","Written\n","Starting epoch 67\n","initialized training.\n","Logging for batch 14\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.47059234976768494\n","Writing\n","Written\n","Starting epoch 68\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.4594959318637848\n","Writing\n","Written\n","Starting epoch 69\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.46690109372138977\n","Writing\n","Written\n","Starting epoch 70\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.47520899772644043\n","Writing\n","Written\n","Starting epoch 71\n","initialized training.\n","Logging for batch 5\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.4897848069667816\n","Writing\n","Written\n","Starting epoch 72\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.47651177644729614\n","Writing\n","Written\n","Starting epoch 73\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.4867917597293854\n","Writing\n","Written\n","Starting epoch 74\n","initialized training.\n","Logging for batch 11\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.4786164462566376\n","Writing\n","Written\n","Starting epoch 75\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.4814814627170563\n","Writing\n","Written\n","Starting epoch 76\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.47863540053367615\n","Writing\n","Written\n","Starting epoch 77\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.4655356705188751\n","Writing\n","Written\n","Starting epoch 78\n","initialized training.\n","Logging for batch 2\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.4749187231063843\n","Writing\n","Written\n","Starting epoch 79\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.46455898880958557\n","Writing\n","Written\n","Starting epoch 80\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.4658495783805847\n","Writing\n","Written\n","Starting epoch 81\n","initialized training.\n","Logging for batch 8\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.4665731191635132\n","Writing\n","Written\n","Starting epoch 82\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.4714629352092743\n","Writing\n","Written\n","Starting epoch 83\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.48565173149108887\n","Writing\n","Written\n","Starting epoch 84\n","initialized training.\n","Logging for batch 14\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.4512155055999756\n","Writing\n","Written\n","Starting epoch 85\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.4718269407749176\n","Writing\n","Written\n","Starting epoch 86\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.48133793473243713\n","Writing\n","Written\n","Starting epoch 87\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.4684118926525116\n","Writing\n","Written\n","Starting epoch 88\n","initialized training.\n","Logging for batch 5\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.4697648882865906\n","Writing\n","Written\n","Starting epoch 89\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.46735623478889465\n","Writing\n","Written\n","Starting epoch 90\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.4641977548599243\n","Writing\n","Written\n","Starting epoch 91\n","initialized training.\n","Logging for batch 11\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.4834129810333252\n","Writing\n","Written\n","Starting epoch 92\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.4807910621166229\n","Writing\n","Written\n","Starting epoch 93\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.4709809124469757\n","Writing\n","Written\n","Starting epoch 94\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.4594118893146515\n","Writing\n","Written\n","Starting epoch 95\n","initialized training.\n","Logging for batch 2\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.47952938079833984\n","Writing\n","Written\n","Starting epoch 96\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.4659217596054077\n","Writing\n","Written\n","Starting epoch 97\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.45261192321777344\n","Writing\n","Written\n","Starting epoch 98\n","initialized training.\n","Logging for batch 8\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.46158936619758606\n","Writing\n","Written\n","Starting epoch 99\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.46515923738479614\n","Writing\n","Written\n","Wow, it feels good to be down here. Done for real\n","Writing\n","Written\n","Now, hopefully on to testing...\n","n_items: 1415\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n","  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"],"name":"stderr"},{"output_type":"stream","text":["setting attribute omit_num_unseen_from_critic to False\n","setting attribute omit_num_seen_from_critic to False\n","setting attribute ac_reg_loss_scaler to 0.0\n","setting attribute lr_ac to 2e-06\n","setting attribute lr_critic to 0.0001\n","setting attribute lr_actor to 0.001\n","setting attribute evaluation_metric to NDCG\n","setting attribute batch_size to 50\n","setting attribute epochs_to_anneal_over to 50\n","setting attribute anneal_cap to 0.2\n","setting attribute input_dim to 1415\n","setting attribute heldout_batch to Tensor(\"IteratorGetNext:1\", shape=(50, 1465), dtype=float32)\n","setting attribute batch_of_users to Tensor(\"IteratorGetNext:0\", shape=(50, 1465), dtype=float32)\n","NOT OMITTING NUM SEEN\n","NOT OMITTING NUM UNSEEN\n","Always doing actor error, of course.\n","number of batch_norm_update_ops: 0\n","changed to 1e-4 from 1e-6, just so I know.\n","Evaluating with NDCG\n","changed to 1e-4 from 1e-6, just so I know.\n","number of BN update ops: 0\n","INFO:tensorflow:Summary name ndcg@100 is illegal; using ndcg_100 instead.\n","Test!\n","INFO:tensorflow:Restoring parameters from /content/gdrive/My Drive/RaCT_CF-master/RaCT_CF-master/checkpoints/ml-100k/multi_vae_with_userinfo/ac_reg_loss_scaler:0.0/actor_reg_loss_scaler:0.01/batch_size:50/batches_to_anneal_over:200000/break_early:False/epochs_to_anneal_over:50/evaluation_metric:NDCG/max_kl:0.2/min_kl:0.0/mode:node2vec_user_info/n_epochs_ac_only:0/n_epochs_pred_and_ac:0/n_epochs_pred_only:100/n_epochs_second_pred:0/omit_num_seen_from_critic:False/omit_num_unseen_from_critic:False/positive_weights:2.0/restore_trained_actor_path:None/verbose:False/version_tag:FULL_RUN_ON_OTHER_DATASETS/model\n","test batch.\n","test batch.\n","test batch.\n","Testing done. That broke it out of the loop.\n","Test UNNORMALIZED DCG@100=2.16172 (1.21294)\n","Test NDCG@100=0.46366 (0.02017)\n","Test Recall@50=0.58656 (0.18764)\n","Test Recall@020=0.42456 (0.18903)\n","Test NDCG@0200=0.50834 (0.13882)\n","Test NDCG@5=0.31008 (0.19032)\n","Test NDCG@3=0.32714 (0.21898)\n","Test NDCG@1=0.37000 (0.34139)\n","On to round 2! Now we'll do the critic.\n","n_items: 1415\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n","  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"],"name":"stderr"},{"output_type":"stream","text":["setting attribute omit_num_unseen_from_critic to False\n","setting attribute omit_num_seen_from_critic to False\n","setting attribute ac_reg_loss_scaler to 0.0\n","setting attribute lr_ac to 2e-06\n","setting attribute lr_critic to 0.0001\n","setting attribute lr_actor to 0.001\n","setting attribute evaluation_metric to NDCG\n","setting attribute batch_size to 50\n","setting attribute epochs_to_anneal_over to 50\n","setting attribute anneal_cap to 0.2\n","setting attribute input_dim to 1415\n","setting attribute heldout_batch to Tensor(\"IteratorGetNext:1\", shape=(50, 1465), dtype=float32)\n","setting attribute batch_of_users to Tensor(\"IteratorGetNext:0\", shape=(50, 1465), dtype=float32)\n","NOT OMITTING NUM SEEN\n","NOT OMITTING NUM UNSEEN\n","Always doing actor error, of course.\n","number of batch_norm_update_ops: 0\n","changed to 1e-4 from 1e-6, just so I know.\n","Evaluating with NDCG\n","changed to 1e-4 from 1e-6, just so I know.\n","number of BN update ops: 0\n","INFO:tensorflow:Summary name ndcg@100 is illegal; using ndcg_100 instead.\n","log directory: /content/gdrive/My Drive/RaCT_CF-master/RaCT_CF-master/logging/ml-100k/multi_vae_with_userinfo/ac_reg_loss_scaler:0.0/actor_reg_loss_scaler:0.01/batch_size:50/batches_to_anneal_over:200000/break_early:False/epochs_to_anneal_over:50/evaluation_metric:NDCG/max_kl:0.2/min_kl:0.0/mode:node2vec_user_info/n_epochs_ac_only:50/n_epochs_pred_and_ac:50/n_epochs_pred_only:0/n_epochs_second_pred:0/omit_num_seen_from_critic:False/omit_num_unseen_from_critic:False/positive_weights:2.0/restore_trained_actor_path:VAE_ACTOR_TRAIN_ml-100k/verbose:False/version_tag:FULL_RUN_ON_OTHER_DATASETS\n","Restoring Actor!\n","INFO:tensorflow:Restoring parameters from VAE_ACTOR_TRAIN_ml-100k/model\n","WARNING:tensorflow:From /content/gdrive/My Drive/RaCT_CF-master/RaCT_CF-master/utils/training.py:331: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n","\n","Starting epoch 0\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5199411511421204\n","new best on metric NDCG. Was -inf, now 0.5199411511421204. Saving\n","Writing\n","Written\n","Starting epoch 1\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5199411511421204\n","Writing\n","Written\n","Starting epoch 2\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5199410915374756\n","Writing\n","Written\n","Starting epoch 3\n","initialized training.\n","Logging for batch 5\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5199411511421204\n","Writing\n","Written\n","Starting epoch 4\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5199410915374756\n","Writing\n","Written\n","Starting epoch 5\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5199411511421204\n","Writing\n","Written\n","Starting epoch 6\n","initialized training.\n","Logging for batch 11\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5199411511421204\n","Writing\n","Written\n","Starting epoch 7\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5199410915374756\n","Writing\n","Written\n","Starting epoch 8\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5199410915374756\n","Writing\n","Written\n","Starting epoch 9\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5199410915374756\n","Writing\n","Written\n","Starting epoch 10\n","initialized training.\n","Logging for batch 2\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5199411511421204\n","Writing\n","Written\n","Starting epoch 11\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5199411511421204\n","Writing\n","Written\n","Starting epoch 12\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5199410915374756\n","Writing\n","Written\n","Starting epoch 13\n","initialized training.\n","Logging for batch 8\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5199411511421204\n","Writing\n","Written\n","Starting epoch 14\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5199410915374756\n","Writing\n","Written\n","Starting epoch 15\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5199411511421204\n","Writing\n","Written\n","Starting epoch 16\n","initialized training.\n","Logging for batch 14\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5199411511421204\n","Writing\n","Written\n","Starting epoch 17\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5199411511421204\n","Writing\n","Written\n","Starting epoch 18\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5199411511421204\n","Writing\n","Written\n","Starting epoch 19\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5199410915374756\n","Writing\n","Written\n","Starting epoch 20\n","initialized training.\n","Logging for batch 5\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5199410915374756\n","Writing\n","Written\n","Starting epoch 21\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5199410915374756\n","Writing\n","Written\n","Starting epoch 22\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5199411511421204\n","Writing\n","Written\n","Starting epoch 23\n","initialized training.\n","Logging for batch 11\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5199411511421204\n","Writing\n","Written\n","Starting epoch 24\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5199411511421204\n","Writing\n","Written\n","Starting epoch 25\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5199411511421204\n","Writing\n","Written\n","Starting epoch 26\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5199411511421204\n","Writing\n","Written\n","Starting epoch 27\n","initialized training.\n","Logging for batch 2\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5199410915374756\n","Writing\n","Written\n","Starting epoch 28\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5199411511421204\n","Writing\n","Written\n","Starting epoch 29\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5199411511421204\n","Writing\n","Written\n","Starting epoch 30\n","initialized training.\n","Logging for batch 8\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5199411511421204\n","Writing\n","Written\n","Starting epoch 31\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5199410915374756\n","Writing\n","Written\n","Starting epoch 32\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5199410915374756\n","Writing\n","Written\n","Starting epoch 33\n","initialized training.\n","Logging for batch 14\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5199411511421204\n","Writing\n","Written\n","Starting epoch 34\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5199410915374756\n","Writing\n","Written\n","Starting epoch 35\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5199411511421204\n","Writing\n","Written\n","Starting epoch 36\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5199410915374756\n","Writing\n","Written\n","Starting epoch 37\n","initialized training.\n","Logging for batch 5\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5199411511421204\n","Writing\n","Written\n","Starting epoch 38\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5199411511421204\n","Writing\n","Written\n","Starting epoch 39\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5199411511421204\n","Writing\n","Written\n","Starting epoch 40\n","initialized training.\n","Logging for batch 11\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5199410915374756\n","Writing\n","Written\n","Starting epoch 41\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5199411511421204\n","Writing\n","Written\n","Starting epoch 42\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5199410915374756\n","Writing\n","Written\n","Starting epoch 43\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5199411511421204\n","Writing\n","Written\n","Starting epoch 44\n","initialized training.\n","Logging for batch 2\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5199411511421204\n","Writing\n","Written\n","Starting epoch 45\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5199411511421204\n","Writing\n","Written\n","Starting epoch 46\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5199410915374756\n","Writing\n","Written\n","Starting epoch 47\n","initialized training.\n","Logging for batch 8\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5199411511421204\n","Writing\n","Written\n","Starting epoch 48\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5199410915374756\n","Writing\n","Written\n","Starting epoch 49\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5199411511421204\n","Writing\n","Written\n","Starting epoch 50\n","initialized training.\n","Logging for batch 14\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5197100639343262\n","Writing\n","Written\n","Starting epoch 51\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5196478366851807\n","Writing\n","Written\n","Starting epoch 52\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5196511745452881\n","Writing\n","Written\n","Starting epoch 53\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5196369886398315\n","Writing\n","Written\n","Starting epoch 54\n","initialized training.\n","Logging for batch 5\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5193164944648743\n","Writing\n","Written\n","Starting epoch 55\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.519498348236084\n","Writing\n","Written\n","Starting epoch 56\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5190430879592896\n","Writing\n","Written\n","Starting epoch 57\n","initialized training.\n","Logging for batch 11\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.518204927444458\n","Writing\n","Written\n","Starting epoch 58\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5188786387443542\n","Writing\n","Written\n","Starting epoch 59\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5180433392524719\n","Writing\n","Written\n","Starting epoch 60\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5178884267807007\n","Writing\n","Written\n","Starting epoch 61\n","initialized training.\n","Logging for batch 2\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5179260969161987\n","Writing\n","Written\n","Starting epoch 62\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5182276964187622\n","Writing\n","Written\n","Starting epoch 63\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5184425115585327\n","Writing\n","Written\n","Starting epoch 64\n","initialized training.\n","Logging for batch 8\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5181352496147156\n","Writing\n","Written\n","Starting epoch 65\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5181373953819275\n","Writing\n","Written\n","Starting epoch 66\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5184913873672485\n","Writing\n","Written\n","Starting epoch 67\n","initialized training.\n","Logging for batch 14\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5197750329971313\n","Writing\n","Written\n","Starting epoch 68\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5186547636985779\n","Writing\n","Written\n","Starting epoch 69\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.518989622592926\n","Writing\n","Written\n","Starting epoch 70\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5186862349510193\n","Writing\n","Written\n","Starting epoch 71\n","initialized training.\n","Logging for batch 5\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5188460350036621\n","Writing\n","Written\n","Starting epoch 72\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5185531377792358\n","Writing\n","Written\n","Starting epoch 73\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5185346007347107\n","Writing\n","Written\n","Starting epoch 74\n","initialized training.\n","Logging for batch 11\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.51883465051651\n","Writing\n","Written\n","Starting epoch 75\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5188524723052979\n","Writing\n","Written\n","Starting epoch 76\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5190798044204712\n","Writing\n","Written\n","Starting epoch 77\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5189908742904663\n","Writing\n","Written\n","Starting epoch 78\n","initialized training.\n","Logging for batch 2\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5189929008483887\n","Writing\n","Written\n","Starting epoch 79\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5189376473426819\n","Writing\n","Written\n","Starting epoch 80\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5184959173202515\n","Writing\n","Written\n","Starting epoch 81\n","initialized training.\n","Logging for batch 8\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5190348625183105\n","Writing\n","Written\n","Starting epoch 82\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5189947485923767\n","Writing\n","Written\n","Starting epoch 83\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5188855528831482\n","Writing\n","Written\n","Starting epoch 84\n","initialized training.\n","Logging for batch 14\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5187672972679138\n","Writing\n","Written\n","Starting epoch 85\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5185679793357849\n","Writing\n","Written\n","Starting epoch 86\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5184644460678101\n","Writing\n","Written\n","Starting epoch 87\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5183709263801575\n","Writing\n","Written\n","Starting epoch 88\n","initialized training.\n","Logging for batch 5\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.518668532371521\n","Writing\n","Written\n","Starting epoch 89\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.518706202507019\n","Writing\n","Written\n","Starting epoch 90\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5182890295982361\n","Writing\n","Written\n","Starting epoch 91\n","initialized training.\n","Logging for batch 11\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.518374502658844\n","Writing\n","Written\n","Starting epoch 92\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5180658102035522\n","Writing\n","Written\n","Starting epoch 93\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.518413782119751\n","Writing\n","Written\n","Starting epoch 94\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5182087421417236\n","Writing\n","Written\n","Starting epoch 95\n","initialized training.\n","Logging for batch 2\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5185677409172058\n","Writing\n","Written\n","Starting epoch 96\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5190351605415344\n","Writing\n","Written\n","Starting epoch 97\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5190570950508118\n","Writing\n","Written\n","Starting epoch 98\n","initialized training.\n","Logging for batch 8\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5190533995628357\n","Writing\n","Written\n","Starting epoch 99\n","initialized training.\n","Epoch Training Done\n","On to validaiton...\n","Validation Done\n","NGCD VAD: 0.5192582607269287\n","Writing\n","Written\n","Wow, it feels good to be down here. Done for real\n","Writing\n","Written\n","Now, hopefully on to testing...\n","n_items: 1415\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n","  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"],"name":"stderr"},{"output_type":"stream","text":["setting attribute omit_num_unseen_from_critic to False\n","setting attribute omit_num_seen_from_critic to False\n","setting attribute ac_reg_loss_scaler to 0.0\n","setting attribute lr_ac to 2e-06\n","setting attribute lr_critic to 0.0001\n","setting attribute lr_actor to 0.001\n","setting attribute evaluation_metric to NDCG\n","setting attribute batch_size to 50\n","setting attribute epochs_to_anneal_over to 50\n","setting attribute anneal_cap to 0.2\n","setting attribute input_dim to 1415\n","setting attribute heldout_batch to Tensor(\"IteratorGetNext:1\", shape=(50, 1465), dtype=float32)\n","setting attribute batch_of_users to Tensor(\"IteratorGetNext:0\", shape=(50, 1465), dtype=float32)\n","NOT OMITTING NUM SEEN\n","NOT OMITTING NUM UNSEEN\n","Always doing actor error, of course.\n","number of batch_norm_update_ops: 0\n","changed to 1e-4 from 1e-6, just so I know.\n","Evaluating with NDCG\n","changed to 1e-4 from 1e-6, just so I know.\n","number of BN update ops: 0\n","INFO:tensorflow:Summary name ndcg@100 is illegal; using ndcg_100 instead.\n","Test!\n","INFO:tensorflow:Restoring parameters from /content/gdrive/My Drive/RaCT_CF-master/RaCT_CF-master/checkpoints/ml-100k/multi_vae_with_userinfo/ac_reg_loss_scaler:0.0/actor_reg_loss_scaler:0.01/batch_size:50/batches_to_anneal_over:200000/break_early:False/epochs_to_anneal_over:50/evaluation_metric:NDCG/max_kl:0.2/min_kl:0.0/mode:node2vec_user_info/n_epochs_ac_only:50/n_epochs_pred_and_ac:50/n_epochs_pred_only:0/n_epochs_second_pred:0/omit_num_seen_from_critic:False/omit_num_unseen_from_critic:False/positive_weights:2.0/restore_trained_actor_path:VAE_ACTOR_TRAIN_ml-100k/verbose:False/version_tag:FULL_RUN_ON_OTHER_DATASETS/model\n","test batch.\n","test batch.\n","test batch.\n","Testing done. That broke it out of the loop.\n","Test UNNORMALIZED DCG@100=2.16172 (1.21294)\n","Test NDCG@100=0.46366 (0.02017)\n","Test Recall@50=0.58656 (0.18764)\n","Test Recall@020=0.42456 (0.18903)\n","Test NDCG@0200=0.50834 (0.13882)\n","Test NDCG@5=0.31008 (0.19032)\n","Test NDCG@3=0.32714 (0.21898)\n","Test NDCG@1=0.37000 (0.34139)\n","Bye bye\n"],"name":"stdout"}]}]}